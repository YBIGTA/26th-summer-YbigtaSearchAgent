
import os
import requests
from dotenv import load_dotenv
from langchain_community.document_loaders import (
    GoogleDriveLoader,
    NotionDBLoader,  # NotionDBLoaderì˜ ì •í™•í•œ ìœ„ì¹˜ë¡œ ìˆ˜ì •
    UnstructuredFileIOLoader,
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

from google.oauth2 import service_account
from googleapiclient.discovery import build

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
load_dotenv()
all_docs = []
# --- 1. Notion ë°ì´í„° ë¡œë“œ ---
print("="*50)
print("Phase 1: Notionì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
try:
    notion_loader = NotionDBLoader(
        integration_token=os.getenv("NOTION_API_KEY"),
        database_id=os.getenv("NOTION_DATABASE_ID"),
        request_timeout_sec=30,
    )
    notion_docs = notion_loader.load()
    
    # --- ğŸ‘‡ [ë¡œê¹… ì¶”ê°€] ë¶ˆëŸ¬ì˜¨ ë¬¸ì„œ ì œëª© ì¶œë ¥ --- ğŸ‘‡
    print(f"âœ… Notionì—ì„œ {len(notion_docs)}ê°œì˜ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:")
    for doc in notion_docs:
        # Notion í˜ì´ì§€ ì œëª©ì€ metadataì˜ 'title'ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
        title = doc.metadata.get('title', 'ì œëª© ì—†ìŒ') 
        print(f"  - ğŸ“„ {title}")
    # --- [ë¡œê¹… ë] ---

    all_docs.extend(notion_docs)

except Exception as e:
    print(f"âŒ Notion ë¡œë“œ ì‹¤íŒ¨: {e}")

# --- 2. Google Drive ë°ì´í„° ë¡œë“œ ---
print("\nGoogle Driveì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")

# --- [ì§„ë‹¨ ì½”ë“œ ì‹œì‘] ---
try:
    folder_id = os.getenv("GDRIVE_FOLDER_ID")
    print(f"ğŸ•µï¸â€â™‚ï¸ ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œìœ¼ë¡œ '{folder_id}' í´ë”ì˜ ëª¨ë“  í•˜ìœ„ í•­ëª©ì„ í™•ì¸í•©ë‹ˆë‹¤...")

    creds = service_account.Credentials.from_service_account_file(
        "gdrive-credentials.json", scopes=["https://www.googleapis.com/auth/drive.readonly"]
    )
    service = build("drive", "v3", credentials=creds)

    def list_files_recursively(folder_id, indent=""):
        try:
            query = f"'{folder_id}' in parents"
            results = service.files().list(q=query, fields="files(id, name, mimeType)").execute()
            items = results.get("files", [])
            for item in items:
                print(f"{indent}ğŸ“„ {item['name']} (ID: {item['id']}, Type: {item['mimeType']})")
                if item["mimeType"] == "application/vnd.google-apps.folder":
                    list_files_recursively(item["id"], indent + "  ")
        except Exception as e:
            print(f"{indent}ğŸš¨ ì˜¤ë¥˜ ë°œìƒ: í•´ë‹¹ í´ë”(ID: {folder_id})ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ({e})")

    list_files_recursively(folder_id)
    print("âœ… íŒŒì¼ ë° í´ë” ëª©ë¡ í™•ì¸ ì™„ë£Œ.")

except Exception as e:
    print(f"ğŸš¨ [ì¹˜ëª…ì  ì˜¤ë¥˜] Google Drive API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
# --- [ì§„ë‹¨ ì½”ë“œ ë] ---


# --- [LangChain ë¡œë” ì‹œì‘] ---
print("\nğŸ“‘ LangChain ë¡œë”ë¡œ ë¬¸ì„œ ë¡œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
gdrive_loader = GoogleDriveLoader(
    folder_id=os.getenv("GDRIVE_FOLDER_ID"),
    service_account_key="gdrive-credentials.json",
    recursive=True,
    file_loader_cls=UnstructuredFileIOLoader,
    file_loader_kwargs={"mode": "elements"},
)

gdrive_docs = gdrive_loader.load()
all_docs.extend(gdrive_docs)
print(f"âœ… LangChainì´ ìµœì¢…ì ìœ¼ë¡œ {len(gdrive_docs)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")


# --- 3. GitHub ì‚¬ìš©ìì˜ ëª¨ë“  ë¦¬í¬ì§€í† ë¦¬ README.md ë¡œë“œ ---
print("="*50)
print("Phase 3: GitHub ì‚¬ìš©ìì˜ ëª¨ë“  ë¦¬í¬ì§€í† ë¦¬ì—ì„œ README.mdë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤...")

USER_NAME = "YBIGTA"  # íƒìƒ‰í•  GitHub ì‚¬ìš©ì ê³„ì • ì´ë¦„
GITHUB_TOKEN = os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN")
HEADERS = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {GITHUB_TOKEN}"
} if GITHUB_TOKEN else {}

def get_all_repos_from_user(user_name):
    """ì§€ì •ëœ GitHub ì‚¬ìš©ìì˜ ëª¨ë“  ê³µê°œ ë¦¬í¬ì§€í† ë¦¬ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    repos = []
    page = 1
    while True:
        url = f"https://api.github.com/users/{user_name}/repos?type=public&page={page}&per_page=100"
        response = requests.get(url, headers=HEADERS)
        response.raise_for_status()
        data = response.json()
        if not data:
            break
        repos.extend([repo['full_name'] for repo in data])
        page += 1
    return repos

github_docs = []
try:
    repo_full_names = get_all_repos_from_user(USER_NAME)
    print(f"ğŸ” ì´ {len(repo_full_names)}ê°œì˜ ë¦¬í¬ì§€í† ë¦¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    
    for repo_name in repo_full_names:
        try:
            loader = GithubFileLoader(
                repo=repo_name,
                access_token=GITHUB_TOKEN,
                file_path="README.md",
                file_filter=lambda file_path: file_path.endswith("README.md")
            )
            docs = loader.load()
            for doc in docs:
                doc.metadata['source'] = f"https://github.com/{repo_name}"
            github_docs.extend(docs)
            print(f"  - âœ… {repo_name}ì˜ README.md ë¡œë“œ ì„±ê³µ")
        except Exception:
            print(f"  - âš ï¸ {repo_name}ì— README.mdê°€ ì—†ê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            continue

    all_docs.extend(github_docs)
    print(f"âœ… GitHubì—ì„œ ì´ {len(github_docs)}ê°œì˜ README.md ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"âŒ GitHub ë¦¬í¬ì§€í† ë¦¬ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

# --- 4. ìµœì¢… DB ìƒì„± ---
print("="*50)
if all_docs:
    print(f"Phase 4: ì´ {len(all_docs)}ê°œì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(all_docs)

    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(texts, embeddings)
    vectorstore.save_local("faiss_index")
    print("\nğŸ‰ ëª¨ë“  ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Vector DBê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("\nâš ï¸ ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ì–´ DBë¥¼ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")