"""
íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (MeetingAnalysisPipeline)

ì˜¤ë””ì˜¤ â†’ STT â†’ í™”ìë¶„ë¦¬ â†’ ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ â†’ ë³´ê³ ì„œ ìƒì„±ì˜ 
ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime
from pathlib import Path
import uuid

logger = logging.getLogger(__name__)

# ì§€ì—° importë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
SpeakerAnalyzer = None



class MeetingAnalysisPipeline:
    """íšŒì˜ ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, 
                 stt_manager=None,
                 speaker_diarizer=None, 
                 agent_orchestrator=None,
                 db_engine=None):
        self.stt_manager = stt_manager
        self.speaker_diarizer = speaker_diarizer
        self.agent_orchestrator = agent_orchestrator
        self.db_engine = db_engine
        
        # íŒŒì´í”„ë¼ì¸ ìƒíƒœ ê´€ë¦¬
        self.pipeline_jobs = {}
        
        # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì •ì˜
        self.pipeline_stages = [
            "file_validation",
            "stt_processing", 
            "speaker_diarization",
            "transcript_processing",
            "speaker_analysis",  # ìƒˆë¡œìš´ í™”ì ì¤‘ì‹¬ ë¶„ì„ ë‹¨ê³„
            "agent_analysis",
            "report_generation",
            "result_storage"
        ]
        
        # ê° ë‹¨ê³„ë³„ ê°€ì¤‘ì¹˜ (ì§„í–‰ë¥  ê³„ì‚°ìš©)
        self.stage_weights = {
            "file_validation": 5,
            "stt_processing": 20,
            "speaker_diarization": 10,
            "transcript_processing": 8,
            "speaker_analysis": 12,  # ìƒˆë¡œìš´ ë‹¨ê³„
            "agent_analysis": 30,
            "report_generation": 12,
            "result_storage": 3
        }
        
        # í™”ì ë¶„ì„ê¸° ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)
        self.speaker_analyzer = None
    
    async def start_analysis(self, 
                           audio_file_path: str,
                           options: Optional[Dict[str, Any]] = None,
                           progress_callback: Optional[Callable] = None) -> str:
        """íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        
        # ì‘ì—… ID ìƒì„±
        job_id = f"pipeline_{uuid.uuid4().hex[:8]}"
        
        # ê¸°ë³¸ ì˜µì…˜ ì„¤ì •
        default_options = {
            "stt_engine": "returnzero",
            "language": "ko", 
            "enable_diarization": True,
            "enable_agents": True,
            "agent_config": {
                "agenda_miner": True,
                "claim_checker": True,
                "counter_arguer": True,
                "evidence_hunter": True,
                "summarizer": True
            }
        }
        pipeline_options = {**default_options, **(options or {})}
        
        # ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
        self.pipeline_jobs[job_id] = {
            "status": "initializing",
            "audio_file": audio_file_path,
            "options": pipeline_options,
            "progress": 0,
            "current_stage": None,
            "started_at": datetime.utcnow().isoformat(),
            "completed_at": None,
            "error": None,
            "results": {},
            "progress_callback": progress_callback,
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            "title": pipeline_options.get("title", f"Meeting_{job_id[:8]}"),
            "original_filename": pipeline_options.get("original_filename", "unknown.wav"),
            "file_size": pipeline_options.get("file_size", 0)
        }
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        asyncio.create_task(self._execute_pipeline(job_id))
        
        logger.info(f"íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {job_id}")
        return job_id
    
    async def _execute_pipeline(self, job_id: str):
        """íŒŒì´í”„ë¼ì¸ ì‹¤ì œ ì‹¤í–‰"""
        job = self.pipeline_jobs[job_id]
        
        try:
            job["status"] = "running"
            
            # 1. íŒŒì¼ ê²€ì¦
            await self._update_progress(job_id, "file_validation", 0)
            validation_result = await self._validate_audio_file(job["audio_file"])
            job["results"]["validation"] = validation_result
            
            if not validation_result["valid"]:
                raise Exception(f"ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {validation_result['error']}")
            
            # 2. STT ì²˜ë¦¬
            await self._update_progress(job_id, "stt_processing", 20)
            stt_result = await self._process_stt(job["audio_file"], job["options"])
            job["results"]["stt"] = stt_result
            
            # 3. í™”ì ë¶„ë¦¬
            if job["options"]["enable_diarization"]:
                await self._update_progress(job_id, "speaker_diarization", 40)
                diarization_result = await self._process_diarization(
                    job["audio_file"], 
                    stt_result.get("segments", [])
                )
                job["results"]["diarization"] = diarization_result
            else:
                job["results"]["diarization"] = {"skipped": True}
            
            # 4. íšŒì˜ë¡ í›„ì²˜ë¦¬
            await self._update_progress(job_id, "transcript_processing", 55)
            transcript = await self._process_transcript(job["results"])
            job["results"]["transcript"] = transcript
            
            # 5. í™”ì ì¤‘ì‹¬ ë¶„ì„
            await self._update_progress(job_id, "speaker_analysis", 63)
            speaker_analysis = await self._process_speaker_analysis(transcript, job["options"])
            job["results"]["speaker_analysis"] = speaker_analysis
            
            # ì¤‘ê°„ ì €ì¥ 1: STT + í™”ì ë¶„ì„ ê²°ê³¼ ì €ì¥
            await self._save_intermediate_results(job_id, job["results"], "speaker_analysis_completed")
            
            # 6. ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„
            if job["options"]["enable_agents"]:
                await self._update_progress(job_id, "agent_analysis", 70)
                logger.info(f"ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ì‹œì‘: {job_id}")
                logger.debug(f"ì „ì‚¬ ê²°ê³¼ ìš”ì•½: í…ìŠ¤íŠ¸ ê¸¸ì´={len(transcript.get('full_text', ''))}, ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜={len(transcript.get('segments', []))}")
                
                agent_results = await self._process_agents(transcript, job["options"]["agent_config"])
                job["results"]["agent_analysis"] = agent_results
                
                logger.info(f"ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ: {job_id}")
                logger.debug(f"ì—ì´ì „íŠ¸ ê²°ê³¼ í‚¤: {list(agent_results.keys()) if agent_results else 'None'}")
                
                # ì¤‘ê°„ ì €ì¥ 2: ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ í›„ ì €ì¥
                await self._save_intermediate_results(job_id, job["results"], "agent_analysis_completed")
            else:
                job["results"]["agent_analysis"] = {"skipped": True}
                logger.info(f"ì—ì´ì „íŠ¸ ë¶„ì„ ìŠ¤í‚µë¨: {job_id}")
            
            # 7. ë³´ê³ ì„œ ìƒì„±
            await self._update_progress(job_id, "report_generation", 92)
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì‹œì‘: {job_id}")
            logger.debug(f"ë³´ê³ ì„œ ìƒì„± ì…ë ¥ ë°ì´í„°: {list(job['results'].keys())}")
            
            report = await self._generate_report(job["results"])
            job["results"]["final_report"] = report
            
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {job_id}")
            logger.debug(f"ë³´ê³ ì„œ êµ¬ì¡°: {list(report.keys()) if report else 'None'}")
            
            # 8. ìµœì¢… ê²°ê³¼ ì €ì¥
            await self._update_progress(job_id, "result_storage", 98)
            storage_result = await self._store_results(job_id, job["results"])
            job["results"]["storage"] = storage_result
            
            # ì™„ë£Œ ì²˜ë¦¬
            job["status"] = "completed"
            job["completed_at"] = datetime.utcnow().isoformat()
            await self._update_progress(job_id, "completed", 100)
            
            logger.info(f"íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {job_id}")
            
        except Exception as e:
            # ì˜¤ë¥˜ ì²˜ë¦¬
            job["status"] = "failed"
            job["error"] = str(e)
            job["completed_at"] = datetime.utcnow().isoformat()
            
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ (job_id: {job_id}): {str(e)}")
            
            if job.get("progress_callback"):
                await job["progress_callback"](job_id, "failed", 0, str(e))
    
    async def _validate_audio_file(self, file_path: str) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦"""
        try:
            path = Path(file_path)
            
            if not path.exists():
                return {"valid": False, "error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
            
            if path.stat().st_size == 0:
                return {"valid": False, "error": "íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            valid_extensions = ['.wav', '.mp3', '.mp4', '.m4a', '.flac', '.ogg']
            if path.suffix.lower() not in valid_extensions:
                return {"valid": False, "error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {path.suffix}"}
            
            return {
                "valid": True,
                "file_size": path.stat().st_size,
                "file_format": path.suffix,
                "file_name": path.name
            }
            
        except Exception as e:
            return {"valid": False, "error": str(e)}
    
    async def _process_stt(self, file_path: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """STT ì²˜ë¦¬"""
        if not self.stt_manager:
            raise Exception("STT ë§¤ë‹ˆì €ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            result = self.stt_manager.transcribe(
                file_path, 
                options.get("stt_engine", "returnzero"),
                options.get("language", "ko")
            )
            
            return {
                "engine_used": options.get("stt_engine", "returnzero"),
                "language": options.get("language", "ko"),
                "segments": result.get("segments", []),
                "full_text": result.get("text", ""),
                "confidence": result.get("confidence", 0.0),
                "duration": result.get("duration", 0.0)
            }
            
        except Exception as e:
            raise Exception(f"STT ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_diarization(self, file_path: str, stt_segments: List[Dict]) -> Dict[str, Any]:
        """í™”ì ë¶„ë¦¬ ì²˜ë¦¬"""
        if not self.speaker_diarizer:
            raise Exception("í™”ì ë¶„ë¦¬ ì‹œìŠ¤í…œì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            segments_with_speakers = await self.speaker_diarizer.diarize_audio(
                file_path, stt_segments
            )
            
            speaker_stats = self.speaker_diarizer.analyze_speaker_distribution(
                segments_with_speakers
            )
            
            return {
                "segments": segments_with_speakers,
                "speaker_statistics": speaker_stats,
                "total_speakers": speaker_stats.get("total_speakers", 0),
                "diarization_stats": self.speaker_diarizer.get_stats()
            }
            
        except Exception as e:
            raise Exception(f"í™”ì ë¶„ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_transcript(self, pipeline_results: Dict[str, Any]) -> Dict[str, Any]:
        """íšŒì˜ë¡ í›„ì²˜ë¦¬"""
        try:
            stt_result = pipeline_results.get("stt", {})
            diarization_result = pipeline_results.get("diarization", {})
            
            # í™”ì ë¶„ë¦¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ STT ê²°ê³¼ë§Œ ì‚¬ìš©
            if not diarization_result.get("skipped", False):
                segments = diarization_result.get("segments", [])
            else:
                segments = stt_result.get("segments", [])
            
            # íšŒì˜ë¡ ë©”íƒ€ë°ì´í„° ìƒì„±
            transcript = {
                "segments": segments,
                "metadata": {
                    "total_duration": stt_result.get("duration", 0.0),
                    "total_segments": len(segments),
                    "speakers_detected": diarization_result.get("total_speakers", 1),
                    "average_confidence": stt_result.get("confidence", 0.0),
                    "language": stt_result.get("language", "ko"),
                    "processing_timestamp": datetime.utcnow().isoformat()
                },
                "full_text": self._generate_full_text(segments),
                "speaker_summary": self._generate_speaker_summary(segments)
            }
            
            return transcript
            
        except Exception as e:
            raise Exception(f"íšŒì˜ë¡ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_speaker_analysis(self, transcript: Dict[str, Any], options: Dict[str, Any]) -> Dict[str, Any]:
        """í™”ì ì¤‘ì‹¬ ë¶„ì„ ì²˜ë¦¬"""
        global SpeakerAnalyzer
        
        try:
            # ì§€ì—° import
            if SpeakerAnalyzer is None:
                try:
                    from agents.speaker_analyzer import SpeakerAnalyzer as SA
                    SpeakerAnalyzer = SA
                except ImportError as e:
                    logger.error(f"SpeakerAnalyzer import ì‹¤íŒ¨: {e}")
                    return {"error": "í™”ì ë¶„ì„ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "skipped": True}
            
            # í™”ì ë¶„ì„ê¸° ì´ˆê¸°í™” (í•„ìš”ì‹œ)
            if self.speaker_analyzer is None:
                # LLM í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ ì „ë‹¬ (ì¶”í›„ ê³ ë„í™” ì‹œ ì‚¬ìš©)
                llm_client = None
                if hasattr(self, 'agent_orchestrator') and self.agent_orchestrator:
                    llm_client = getattr(self.agent_orchestrator, 'llm_client', None)
                
                self.speaker_analyzer = SpeakerAnalyzer(llm_client)
                logger.info("âœ… í™”ì ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            
            # ë¶„ì„ ì‹¤í–‰
            logger.info("ğŸ¤ í™”ì ì¤‘ì‹¬ ë¶„ì„ ì‹œì‘")
            analysis_result = await self.speaker_analyzer.analyze(transcript)
            
            logger.info(f"âœ… í™”ì ì¤‘ì‹¬ ë¶„ì„ ì™„ë£Œ: {analysis_result.get('total_speakers', 0)}ëª… ë¶„ì„")
            return analysis_result
            
        except Exception as e:
            logger.error(f"í™”ì ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {
                "error": f"í™”ì ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "skipped": True,
                "fallback_data": {
                    "total_speakers": len(transcript.get("speaker_summary", {}).get("speakers", {})),
                    "analysis_timestamp": datetime.utcnow().isoformat()
                }
            }
    
    async def _process_agents(self, transcript: Dict[str, Any], agent_config: Dict[str, bool]) -> Dict[str, Any]:
        """ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„"""
        if not self.agent_orchestrator:
            logger.warning("ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return self._create_fallback_agent_results(transcript)
        
        try:
            # ì—ì´ì „íŠ¸ë³„ í™œì„±í™” ìƒíƒœì— ë”°ë¼ ë¶„ì„ ì‹¤í–‰
            agent_results = {}
            
            meeting_data = {
                "transcript": transcript.get("full_text", ""),
                "speakers": transcript.get("speakers", []),
                "timeline": transcript.get("segments", []),
                "metadata": transcript.get("metadata", {}),
                "content": transcript.get("full_text", "")
            }
            
            logger.info(f"ì—ì´ì „íŠ¸ ë¶„ì„ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
            logger.info(f"  - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(meeting_data['transcript'])} ë¬¸ì")
            logger.info(f"  - ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(meeting_data['timeline'])} ê°œ")
            logger.info(f"  - í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {meeting_data['transcript'][:300]}...")
            
            if len(meeting_data['transcript']) == 0:
                logger.error("ğŸš¨ ê²½ê³ : ì—ì´ì „íŠ¸ì— ì „ë‹¬ë˜ëŠ” í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
                logger.error(f"ì›ë³¸ transcript êµ¬ì¡°: {list(transcript.keys())}")
                logger.error(f"full_text ê°’: '{transcript.get('full_text', 'KEY_NOT_FOUND')}'")
                logger.error(f"segments ê¸¸ì´: {len(transcript.get('segments', []))}")
            
            # ê° ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰ (ì‹¤ì œë¡œëŠ” ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥)
            if agent_config.get("agenda_miner", True):
                logger.info("AgendaMiner ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["agendas"] = await self.agent_orchestrator.agenda_miner.analyze(
                        meeting_data
                    )
                    logger.info("AgendaMiner ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"AgendaMiner ì‹¤íŒ¨: {str(e)}")
                    agent_results["agendas"] = {"error": str(e), "agendas": []}
            
            if agent_config.get("claim_checker", True):
                logger.info("ClaimChecker ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["claims"] = await self.agent_orchestrator.claim_checker.analyze(
                        meeting_data
                    )
                    logger.info("ClaimChecker ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"ClaimChecker ì‹¤íŒ¨: {str(e)}")
                    agent_results["claims"] = {"error": str(e), "claims": []}
            
            if agent_config.get("counter_arguer", True):
                logger.info("CounterArguer ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["counter_arguments"] = await self.agent_orchestrator.counter_arguer.analyze(
                        meeting_data
                    )
                    logger.info("CounterArguer ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"CounterArguer ì‹¤íŒ¨: {str(e)}")
                    agent_results["counter_arguments"] = {"error": str(e), "counter_arguments": []}
            
            if agent_config.get("evidence_hunter", True):
                logger.info("EvidenceHunter ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["evidence"] = await self.agent_orchestrator.evidence_hunter.search_and_verify(
                        meeting_data["content"], meeting_data
                    )
                    logger.info("EvidenceHunter ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"EvidenceHunter ì‹¤íŒ¨: {str(e)}")
                    agent_results["evidence"] = {"error": str(e), "evidence_found": []}
            
            if agent_config.get("summarizer", True):
                logger.info("Summarizer ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["summary"] = await self.agent_orchestrator.summarizer.generate_report(
                        agent_results
                    )
                    logger.info("Summarizer ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"Summarizer ì‹¤íŒ¨: {str(e)}")
                    agent_results["summary"] = {"error": str(e), "action_items": [], "executive_summary": {}}
            
            logger.info(f"ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ. ê²°ê³¼ í‚¤: {list(agent_results.keys())}")
            return agent_results
            
        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ ë¶„ì„ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì—ì´ì „íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def _generate_report(self, pipeline_results: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        try:
            transcript = pipeline_results.get("transcript", {})
            agent_results = pipeline_results.get("agent_analysis", {})
            
            logger.info(f"ë³´ê³ ì„œ ìƒì„± - ì…ë ¥ ì²´í¬:")
            logger.info(f"  - transcript í‚¤: {list(transcript.keys()) if transcript else 'None'}")
            logger.info(f"  - agent_results í‚¤: {list(agent_results.keys()) if agent_results else 'None'}")
            
            # ê° ë‹¨ê³„ë³„ ë°ì´í„° ì¶”ì¶œ
            meeting_overview = self._generate_meeting_overview(transcript)
            logger.debug(f"meeting_overview: {meeting_overview}")
            
            key_findings = self._extract_key_findings(agent_results)
            logger.debug(f"key_findings: {len(key_findings)}ê°œ")
            
            action_items = self._extract_action_items(agent_results)
            logger.debug(f"action_items: {len(action_items)}ê°œ")
            
            recommendations = self._generate_recommendations(agent_results)
            logger.debug(f"recommendations: {len(recommendations)}ê°œ")
            
            report = {
                "executive_summary": {
                    "meeting_overview": meeting_overview,
                    "key_findings": key_findings,
                    "action_items": action_items,
                    "recommendations": recommendations
                },
                "detailed_analysis": {
                    "transcript_analysis": transcript.get("metadata", {}),
                    "speaker_analysis": transcript.get("speaker_summary", {}),
                    "content_analysis": agent_results
                },
                "technical_details": {
                    "processing_pipeline": {
                        "stt_engine": pipeline_results.get("stt", {}).get("engine_used"),
                        "diarization_enabled": not pipeline_results.get("diarization", {}).get("skipped", True),
                        "agents_used": list(agent_results.keys()) if agent_results else []
                    },
                    "quality_metrics": {
                        "stt_confidence": pipeline_results.get("stt", {}).get("confidence", 0.0),
                        "speakers_detected": transcript.get("metadata", {}).get("speakers_detected", 1),
                        "processing_time": None  # TODO: ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                    }
                },
                "generated_at": datetime.utcnow().isoformat(),
                "format_version": "1.0"
            }
            
            logger.info("ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            logger.debug(f"ìµœì¢… ë³´ê³ ì„œ í‚¤: {list(report.keys())}")
            return report
            
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ ìƒì„¸: {str(e)}")
            logger.exception("ë³´ê³ ì„œ ìƒì„± ì˜ˆì™¸ ìƒì„¸:")
            raise Exception(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    async def _store_results(self, job_id: str, results: Dict[str, Any]) -> Dict[str, Any]:
        """ê²°ê³¼ ì €ì¥ - ì§ì ‘ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        if not self.db_engine:
            logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {"saved": False, "error": "ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ì´ ì—†ìŒ"}
            
        try:
            # Import database models inside function
            try:
                from db.models import get_session, MeetingReport
            except ImportError as e:
                logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return {"saved": False, "error": "ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ import ì‹¤íŒ¨"}
            
            job = self.pipeline_jobs.get(job_id, {})
            
            # ì„¸ì…˜ ìƒì„±
            session = get_session(self.db_engine)
            
            try:
                # ê¸°ì¡´ ë³´ê³ ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
                existing_report = session.query(MeetingReport).filter_by(job_id=job_id).first()
                
                if existing_report:
                    # ê¸°ì¡´ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸
                    meeting_report = existing_report
                else:
                    # ìƒˆ ë³´ê³ ì„œ ìƒì„±
                    meeting_report = MeetingReport(job_id=job_id)
                    session.add(meeting_report)
                
                # ë³´ê³ ì„œ í•„ë“œ ì—…ë°ì´íŠ¸
                meeting_report.title = job.get("title", f"Meeting_{job_id[:8]}")
                meeting_report.original_filename = job.get("original_filename", "unknown.wav")
                meeting_report.file_size = job.get("file_size", 0)
                meeting_report.duration_seconds = results.get("stt", {}).get("duration", 0)
                meeting_report.num_speakers = len(results.get("diarization", {}).get("speakers", []))
                meeting_report.raw_results = results
                meeting_report.executive_summary = results.get("final_report", {}).get("executive_summary", {})
                meeting_report.agendas = results.get("agent_analysis", {}).get("agendas", {})
                meeting_report.claims = results.get("agent_analysis", {}).get("claims", {})
                meeting_report.counter_arguments = results.get("agent_analysis", {}).get("counter_arguments", {})
                meeting_report.evidence = results.get("agent_analysis", {}).get("evidence", {})
                meeting_report.final_report = results.get("final_report", {})
                meeting_report.status = "completed"
                meeting_report.progress = 100
                meeting_report.current_stage = "completed"
                meeting_report.completed_at = datetime.now()
                meeting_report.updated_at = datetime.now()
                
                session.commit()
                
                logger.info(f"âœ… ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {job_id}")
                return {
                    "saved": True,
                    "report_id": meeting_report.id,
                    "job_id": job_id
                }
                
            finally:
                session.close()
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"saved": False, "error": str(e)}
    
    async def _save_intermediate_results(self, job_id: str, results: Dict[str, Any], stage: str):
        """ì¤‘ê°„ ê²°ê³¼ ì‹¤ì‹œê°„ ì €ì¥ - ë¶€ë¶„ ì™„ë£Œ ìƒíƒœì—ì„œë„ ë°ì´í„° ë³´ì¡´"""
        if not self.db_engine:
            logger.warning(f"ì¤‘ê°„ ì €ì¥ ìŠ¤í‚µ (DB ì—†ìŒ): {job_id} - {stage}")
            return
        
        try:
            # Import database models inside function
            try:
                from db.models import get_session, MeetingReport
            except ImportError as e:
                logger.error(f"âŒ DB ëª¨ë¸ import ì‹¤íŒ¨ (ì¤‘ê°„ ì €ì¥): {e}")
                return
            
            job = self.pipeline_jobs.get(job_id, {})
            
            # ì„¸ì…˜ ìƒì„±
            session = get_session(self.db_engine)
            
            try:
                # ê¸°ì¡´ ë ˆì½”ë“œ í™•ì¸/ìƒì„±
                meeting_report = session.query(MeetingReport).filter_by(job_id=job_id).first()
                
                if not meeting_report:
                    # ìƒˆ ë ˆì½”ë“œ ìƒì„±
                    meeting_report = MeetingReport(job_id=job_id)
                    session.add(meeting_report)
                
                # ê¸°ë³¸ ì •ë³´ ì—…ë°ì´íŠ¸
                meeting_report.title = job.get("title", f"Meeting_{job_id[:8]}")
                meeting_report.original_filename = job.get("original_filename", "unknown.wav")
                meeting_report.file_size = job.get("file_size", 0)
                meeting_report.current_stage = stage
                meeting_report.progress = job.get("progress", 0)
                meeting_report.status = "processing"
                meeting_report.updated_at = datetime.now()
                
                # ë‹¨ê³„ë³„ ê²°ê³¼ ì €ì¥
                if stage == "speaker_analysis_completed":
                    # STT + í™”ì ë¶„ì„ ê²°ê³¼ ì €ì¥
                    meeting_report.duration_seconds = results.get("stt", {}).get("duration", 0)
                    meeting_report.num_speakers = results.get("speaker_analysis", {}).get("total_speakers", 0)
                    meeting_report.raw_results = {
                        "stt": results.get("stt", {}),
                        "diarization": results.get("diarization", {}),
                        "transcript": results.get("transcript", {}),
                        "speaker_analysis": results.get("speaker_analysis", {})
                    }
                
                elif stage == "agent_analysis_completed":
                    # ì—ì´ì „íŠ¸ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                    existing_results = meeting_report.raw_results or {}
                    existing_results.update({
                        "agent_analysis": results.get("agent_analysis", {})
                    })
                    meeting_report.raw_results = existing_results
                    
                    # ì—ì´ì „íŠ¸ë³„ ê²°ê³¼ ì €ì¥
                    agent_results = results.get("agent_analysis", {})
                    meeting_report.agendas = agent_results.get("agendas", {})
                    meeting_report.claims = agent_results.get("claims", {})
                    meeting_report.counter_arguments = agent_results.get("counter_arguments", {})
                    meeting_report.evidence = agent_results.get("evidence", {})
                
                session.commit()
                logger.info(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {job_id} - {stage}")
                
            finally:
                session.close()
                
        except Exception as e:
            logger.error(f"âŒ ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨: {job_id} - {stage}: {str(e)}")
            # ì¤‘ê°„ ì €ì¥ ì‹¤íŒ¨ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ
    
    def _generate_full_text(self, segments: List[Dict[str, Any]]) -> str:
        """ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ìƒì„± - ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›"""
        logger.info(f"_generate_full_text: ë°›ì€ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜={len(segments)}")
        if segments:
            logger.info(f"ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ êµ¬ì¡°: {list(segments[0].keys())}")
        
        # ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ í•„ë“œëª… ìš°ì„ ìˆœìœ„ ì§€ì›
        text_fields = ["text", "msg", "content", "transcript"]
        full_text_parts = []
        
        for seg in segments:
            text_content = None
            
            # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ í…ìŠ¤íŠ¸ í•„ë“œ ì°¾ê¸°
            for field in text_fields:
                if field in seg and seg[field] and seg[field].strip():
                    text_content = seg[field].strip()
                    break
            
            if text_content:
                full_text_parts.append(text_content)
                logger.debug(f"ì„¸ê·¸ë¨¼íŠ¸ í…ìŠ¤íŠ¸ ì¶”ê°€: '{text_content[:50]}...'")
            else:
                logger.warning(f"ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {list(seg.keys())}")
        
        full_text = " ".join(full_text_parts)
        
        logger.info(f"âœ… í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: {len(full_text)} ë¬¸ì, {len(full_text_parts)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        if len(full_text) == 0:
            logger.error("ğŸš¨ ê²½ê³ : ìƒì„±ëœ ì „ì²´ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            logger.error(f"ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ìƒ˜í”Œ: {segments[:3] if segments else 'ì—†ìŒ'}")
        else:
            logger.info(f"ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {full_text[:200]}...")
        
        return full_text
    
    def _generate_speaker_summary(self, segments: List[Dict[str, Any]]) -> Dict[str, Any]:
        """í™”ìë³„ ìš”ì•½ ìƒì„± - í–¥ìƒëœ í†µê³„ ì •ë³´"""
        speaker_data = {}
        total_duration = 0.0
        total_words = 0
        
        # ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›
        text_fields = ["text", "msg", "content"]
        speaker_fields = ["speaker", "spk"]
        duration_fields = ["duration", "length"]
        
        for seg in segments:
            # í™”ì ì •ë³´ ì¶”ì¶œ
            speaker = None
            for field in speaker_fields:
                if field in seg and seg[field] is not None:
                    speaker_value = seg[field]
                    if isinstance(speaker_value, int):
                        speaker = f"Speaker {speaker_value}"
                    else:
                        speaker = str(speaker_value)
                    break
            
            if not speaker:
                speaker = "Unknown"
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text_content = ""
            for field in text_fields:
                if field in seg and seg[field]:
                    text_content = seg[field]
                    break
            
            # ì§€ì†ì‹œê°„ ì¶”ì¶œ
            duration = 0.0
            for field in duration_fields:
                if field in seg and isinstance(seg[field], (int, float)):
                    duration = float(seg[field])
                    break
            
            # ì‹œê°„ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ê³„ì‚°
            if duration == 0.0 and "start" in seg and "end" in seg:
                try:
                    duration = float(seg["end"]) - float(seg["start"])
                except (ValueError, TypeError):
                    duration = 0.0
            
            # í™”ìë³„ ë°ì´í„° ì§‘ê³„
            if speaker not in speaker_data:
                speaker_data[speaker] = {
                    "utterance_count": 0,
                    "total_words": 0,
                    "total_duration": 0.0,
                    "average_utterance_length": 0.0,
                    "speaking_percentage": 0.0
                }
            
            word_count = len(text_content.split()) if text_content else 0
            
            speaker_data[speaker]["utterance_count"] += 1
            speaker_data[speaker]["total_words"] += word_count
            speaker_data[speaker]["total_duration"] += duration
            
            total_duration += duration
            total_words += word_count
        
        # ë¹„ìœ¨ ë° í‰ê·  ê³„ì‚°
        for speaker, data in speaker_data.items():
            if data["utterance_count"] > 0:
                data["average_utterance_length"] = data["total_words"] / data["utterance_count"]
            
            if total_duration > 0:
                data["speaking_percentage"] = (data["total_duration"] / total_duration) * 100
        
        # ì „ì²´ í†µê³„ ì¶”ê°€
        summary_with_totals = {
            "speakers": speaker_data,
            "total_speakers": len(speaker_data),
            "total_duration": total_duration,
            "total_words": total_words,
            "most_active_speaker": max(speaker_data.keys(), 
                                     key=lambda s: speaker_data[s]["total_words"]) if speaker_data else None
        }
        
        logger.info(f"âœ… í™”ìë³„ ìš”ì•½ ìƒì„±: {len(speaker_data)}ëª…, ì´ {total_duration:.1f}ì´ˆ")
        
        return summary_with_totals
    
    def _generate_meeting_overview(self, transcript: Dict[str, Any]) -> str:
        """íšŒì˜ ê°œìš” ìƒì„±"""
        metadata = transcript.get("metadata", {})
        duration = metadata.get("total_duration", 0)
        speakers = metadata.get("speakers_detected", 1)
        
        return f"ì´ {duration:.1f}ì´ˆ ê¸¸ì´ì˜ íšŒì˜ì—ì„œ {speakers}ëª…ì˜ í™”ìê°€ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤."
    
    def _extract_key_findings(self, agent_results: Dict[str, Any]) -> List[str]:
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ì¶”ì¶œ"""
        findings = []
        
        if "agendas" in agent_results:
            agendas = agent_results["agendas"].get("agendas", [])
            findings.extend([f"ì£¼ìš” ì•ˆê±´: {agenda}" for agenda in agendas[:3]])
        
        if "claims" in agent_results:
            claims = agent_results["claims"].get("verified_claims", [])
            findings.extend([f"ê²€ì¦ëœ ì£¼ì¥: {claim}" for claim in claims[:2]])
        
        return findings or ["ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."]
    
    def _extract_action_items(self, agent_results: Dict[str, Any]) -> List[str]:
        """ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        if "summary" in agent_results:
            return agent_results["summary"].get("action_items", [])
        return ["ì•¡ì…˜ ì•„ì´í…œì´ ì‹ë³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
    
    def _generate_recommendations(self, agent_results: Dict[str, Any]) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if "counter_arguments" in agent_results:
            counter_args = agent_results["counter_arguments"].get("counter_arguments", [])
            if counter_args:
                recommendations.append("ì œì‹œëœ ë°˜ë°• ì˜ê²¬ë“¤ì„ ê²€í† í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        if "evidence" in agent_results:
            evidence = agent_results["evidence"].get("evidence_found", [])
            if evidence:
                recommendations.append("ì¶”ê°€ ì¦ê±° ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ì˜ì‚¬ê²°ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        return recommendations or ["íŠ¹ë³„í•œ ê¶Œì¥ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."]
    
    async def _update_progress(self, job_id: str, stage: str, progress: int):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        job = self.pipeline_jobs[job_id]
        job["current_stage"] = stage
        job["progress"] = progress
        
        # ì½œë°± í˜¸ì¶œ
        if job.get("progress_callback"):
            await job["progress_callback"](job_id, stage, progress, None)
    
    def get_job_status(self, job_id: str) -> Optional[Dict[str, Any]]:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        return self.pipeline_jobs.get(job_id)
    
    def get_job_results(self, job_id: str) -> Optional[Dict[str, Any]]:
        """ì‘ì—… ê²°ê³¼ ì¡°íšŒ"""
        job = self.pipeline_jobs.get(job_id)
        return job.get("results") if job else None
    
    def get_estimated_remaining_time(self, job_id: str) -> Optional[int]:
        """ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)"""
        job = self.pipeline_jobs.get(job_id)
        if not job:
            return None
        
        progress = job.get("progress", 0)
        if progress <= 0:
            return None
        
        # ì‹œì‘ ì‹œê°„ë¶€í„° í˜„ì¬ê¹Œì§€ ê²½ê³¼ ì‹œê°„ ê³„ì‚°
        started_at = job.get("started_at")
        if not started_at:
            return None
        
        try:
            start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
            elapsed_seconds = (datetime.utcnow() - start_time.replace(tzinfo=None)).total_seconds()
            
            # ì§„í–‰ë¥  ê¸°ë°˜ìœ¼ë¡œ ì˜ˆìƒ ì´ ì‹œê°„ ê³„ì‚°
            if progress > 0:
                estimated_total_time = elapsed_seconds / (progress / 100)
                remaining_time = estimated_total_time - elapsed_seconds
                return max(0, int(remaining_time))
        except:
            pass
        
        return None
    
    def cancel_job(self, job_id: str) -> bool:
        """ì‘ì—… ì·¨ì†Œ"""
        if job_id in self.pipeline_jobs:
            job = self.pipeline_jobs[job_id]
            if job["status"] in ["running", "initializing"]:
                job["status"] = "cancelled"
                job["completed_at"] = datetime.utcnow().isoformat()
                return True
        return False
    
    def cleanup_completed_jobs(self, max_age_hours: int = 24):
        """ì™„ë£Œëœ ì‘ì—… ì •ë¦¬"""
        current_time = datetime.utcnow()
        jobs_to_remove = []
        
        for job_id, job in self.pipeline_jobs.items():
            if job["status"] in ["completed", "failed", "cancelled"]:
                completed_at = datetime.fromisoformat(job["completed_at"])
                age_hours = (current_time - completed_at).total_seconds() / 3600
                
                if age_hours > max_age_hours:
                    jobs_to_remove.append(job_id)
        
        for job_id in jobs_to_remove:
            del self.pipeline_jobs[job_id]
        
        return len(jobs_to_remove)
    
    def _create_fallback_agent_results(self, transcript: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ì—†ì´ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        logger.info("ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
        
        full_text = transcript.get("full_text", "")
        segments = transcript.get("segments", [])
        speakers = transcript.get("speaker_summary", {})
        
        # ê¸°ë³¸ ì•„ì  ë‹¤
        basic_agenda = {
            "id": 1,
            "title": "íšŒì˜ ì£¼ìš” ë‚´ìš©",
            "description": f"ì´ {len(full_text)}ìì˜ íšŒì˜ë¡ì´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "category": "discussion",
            "priority": "medium",
            "related_topics": [],
            "outcomes": [],
            "action_items": [],
            "discussion_points": ["íšŒì˜ ë‚´ìš© ìš”ì•½ì´ í•„ìš”í•©ë‹ˆë‹¤."]
        }
        
        # ê¸°ë³¸ ì£¼ì¥ ë¶„ì„
        basic_claim = {
            "id": 1,
            "speaker": "ì•Œ ìˆ˜ ì—†ìŒ",
            "claim": "ì£¼ìš” ë…¼ì˜ ì‚¬í•­ì´ ìˆì—ˆìŠµë‹ˆë‹¤.",
            "type": "opinion",
            "confidence_level": "low",
            "evidence": [],
            "context": "ì „ì²´ íšŒì˜ ë§¥ë½",
            "implications": [],
            "related_claims": [],
            "time_reference": "íšŒì˜ ì „ë°˜"
        }
        
        return {
            "agendas": {
                "agendas": [basic_agenda],
                "confidence": 0.3,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "claims": {
                "claims": [basic_claim],
                "confidence": 0.3,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "counter_arguments": {
                "counter_arguments": [],
                "confidence": 0.0,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "evidence": {
                "evidence_found": [],
                "confidence": 0.0,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "summary": {
                "executive_summary": {
                    "overview": f"ì´ {len(segments)}ê°œ ë°œí™”ê°€ í¬í•¨ëœ íšŒì˜ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "participants": len(speakers),
                    "duration": transcript.get("metadata", {}).get("total_duration", 0)
                },
                "action_items": [],
                "key_decisions": [],
                "next_steps": [],
                "confidence": 0.3,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            }
        }