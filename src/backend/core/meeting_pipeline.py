"""
íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (MeetingAnalysisPipeline)

ì˜¤ë””ì˜¤ â†’ STT â†’ í™”ìë¶„ë¦¬ â†’ ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ â†’ ë³´ê³ ì„œ ìƒì„±ì˜ 
ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime
from pathlib import Path
import uuid

logger = logging.getLogger(__name__)



class MeetingAnalysisPipeline:
    """íšŒì˜ ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, 
                 stt_manager=None,
                 speaker_diarizer=None, 
                 agent_orchestrator=None,
                 db_engine=None):
        self.stt_manager = stt_manager
        self.speaker_diarizer = speaker_diarizer
        self.agent_orchestrator = agent_orchestrator
        self.db_engine = db_engine
        
        # íŒŒì´í”„ë¼ì¸ ìƒíƒœ ê´€ë¦¬
        self.pipeline_jobs = {}
        
        # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì •ì˜
        self.pipeline_stages = [
            "file_validation",
            "stt_processing", 
            "speaker_diarization",
            "transcript_processing",
            "agent_analysis",
            "report_generation",
            "result_storage"
        ]
        
        # ê° ë‹¨ê³„ë³„ ê°€ì¤‘ì¹˜ (ì§„í–‰ë¥  ê³„ì‚°ìš©)
        self.stage_weights = {
            "file_validation": 5,
            "stt_processing": 25,
            "speaker_diarization": 15,
            "transcript_processing": 10,
            "agent_analysis": 35,
            "report_generation": 8,
            "result_storage": 2
        }
    
    async def start_analysis(self, 
                           audio_file_path: str,
                           options: Optional[Dict[str, Any]] = None,
                           progress_callback: Optional[Callable] = None) -> str:
        """íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        
        # ì‘ì—… ID ìƒì„±
        job_id = f"pipeline_{uuid.uuid4().hex[:8]}"
        
        # ê¸°ë³¸ ì˜µì…˜ ì„¤ì •
        default_options = {
            "stt_engine": "returnzero",
            "language": "ko", 
            "enable_diarization": True,
            "enable_agents": True,
            "agent_config": {
                "agenda_miner": True,
                "claim_checker": True,
                "counter_arguer": True,
                "evidence_hunter": True,
                "summarizer": True
            }
        }
        pipeline_options = {**default_options, **(options or {})}
        
        # ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
        self.pipeline_jobs[job_id] = {
            "status": "initializing",
            "audio_file": audio_file_path,
            "options": pipeline_options,
            "progress": 0,
            "current_stage": None,
            "started_at": datetime.utcnow().isoformat(),
            "completed_at": None,
            "error": None,
            "results": {},
            "progress_callback": progress_callback,
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            "title": pipeline_options.get("title", f"Meeting_{job_id[:8]}"),
            "original_filename": pipeline_options.get("original_filename", "unknown.wav"),
            "file_size": pipeline_options.get("file_size", 0)
        }
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        asyncio.create_task(self._execute_pipeline(job_id))
        
        logger.info(f"íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {job_id}")
        return job_id
    
    async def _execute_pipeline(self, job_id: str):
        """íŒŒì´í”„ë¼ì¸ ì‹¤ì œ ì‹¤í–‰"""
        job = self.pipeline_jobs[job_id]
        
        try:
            job["status"] = "running"
            
            # 1. íŒŒì¼ ê²€ì¦
            await self._update_progress(job_id, "file_validation", 0)
            validation_result = await self._validate_audio_file(job["audio_file"])
            job["results"]["validation"] = validation_result
            
            if not validation_result["valid"]:
                raise Exception(f"ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {validation_result['error']}")
            
            # 2. STT ì²˜ë¦¬
            await self._update_progress(job_id, "stt_processing", 20)
            stt_result = await self._process_stt(job["audio_file"], job["options"])
            job["results"]["stt"] = stt_result
            
            # 3. í™”ì ë¶„ë¦¬
            if job["options"]["enable_diarization"]:
                await self._update_progress(job_id, "speaker_diarization", 40)
                diarization_result = await self._process_diarization(
                    job["audio_file"], 
                    stt_result.get("segments", [])
                )
                job["results"]["diarization"] = diarization_result
            else:
                job["results"]["diarization"] = {"skipped": True}
            
            # 4. íšŒì˜ë¡ í›„ì²˜ë¦¬
            await self._update_progress(job_id, "transcript_processing", 55)
            transcript = await self._process_transcript(job["results"])
            job["results"]["transcript"] = transcript
            
            # 5. ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„
            if job["options"]["enable_agents"]:
                await self._update_progress(job_id, "agent_analysis", 65)
                logger.info(f"ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ì‹œì‘: {job_id}")
                logger.debug(f"ì „ì‚¬ ê²°ê³¼ ìš”ì•½: í…ìŠ¤íŠ¸ ê¸¸ì´={len(transcript.get('full_text', ''))}, ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜={len(transcript.get('segments', []))}")
                
                agent_results = await self._process_agents(transcript, job["options"]["agent_config"])
                job["results"]["agent_analysis"] = agent_results
                
                logger.info(f"ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ: {job_id}")
                logger.debug(f"ì—ì´ì „íŠ¸ ê²°ê³¼ í‚¤: {list(agent_results.keys()) if agent_results else 'None'}")
            else:
                job["results"]["agent_analysis"] = {"skipped": True}
                logger.info(f"ì—ì´ì „íŠ¸ ë¶„ì„ ìŠ¤í‚µë¨: {job_id}")
            
            # 6. ë³´ê³ ì„œ ìƒì„±
            await self._update_progress(job_id, "report_generation", 92)
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì‹œì‘: {job_id}")
            logger.debug(f"ë³´ê³ ì„œ ìƒì„± ì…ë ¥ ë°ì´í„°: {list(job['results'].keys())}")
            
            report = await self._generate_report(job["results"])
            job["results"]["final_report"] = report
            
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {job_id}")
            logger.debug(f"ë³´ê³ ì„œ êµ¬ì¡°: {list(report.keys()) if report else 'None'}")
            
            # 7. ê²°ê³¼ ì €ì¥
            await self._update_progress(job_id, "result_storage", 98)
            storage_result = await self._store_results(job_id, job["results"])
            job["results"]["storage"] = storage_result
            
            # ì™„ë£Œ ì²˜ë¦¬
            job["status"] = "completed"
            job["completed_at"] = datetime.utcnow().isoformat()
            await self._update_progress(job_id, "completed", 100)
            
            logger.info(f"íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {job_id}")
            
        except Exception as e:
            # ì˜¤ë¥˜ ì²˜ë¦¬
            job["status"] = "failed"
            job["error"] = str(e)
            job["completed_at"] = datetime.utcnow().isoformat()
            
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ (job_id: {job_id}): {str(e)}")
            
            if job.get("progress_callback"):
                await job["progress_callback"](job_id, "failed", 0, str(e))
    
    async def _validate_audio_file(self, file_path: str) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦"""
        try:
            path = Path(file_path)
            
            if not path.exists():
                return {"valid": False, "error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
            
            if path.stat().st_size == 0:
                return {"valid": False, "error": "íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            valid_extensions = ['.wav', '.mp3', '.mp4', '.m4a', '.flac', '.ogg']
            if path.suffix.lower() not in valid_extensions:
                return {"valid": False, "error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {path.suffix}"}
            
            return {
                "valid": True,
                "file_size": path.stat().st_size,
                "file_format": path.suffix,
                "file_name": path.name
            }
            
        except Exception as e:
            return {"valid": False, "error": str(e)}
    
    async def _process_stt(self, file_path: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """STT ì²˜ë¦¬"""
        if not self.stt_manager:
            raise Exception("STT ë§¤ë‹ˆì €ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            result = self.stt_manager.transcribe(
                file_path, 
                options.get("stt_engine", "returnzero"),
                options.get("language", "ko")
            )
            
            return {
                "engine_used": options.get("stt_engine", "returnzero"),
                "language": options.get("language", "ko"),
                "segments": result.get("segments", []),
                "full_text": result.get("text", ""),
                "confidence": result.get("confidence", 0.0),
                "duration": result.get("duration", 0.0)
            }
            
        except Exception as e:
            raise Exception(f"STT ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_diarization(self, file_path: str, stt_segments: List[Dict]) -> Dict[str, Any]:
        """í™”ì ë¶„ë¦¬ ì²˜ë¦¬"""
        if not self.speaker_diarizer:
            raise Exception("í™”ì ë¶„ë¦¬ ì‹œìŠ¤í…œì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            segments_with_speakers = await self.speaker_diarizer.diarize_audio(
                file_path, stt_segments
            )
            
            speaker_stats = self.speaker_diarizer.analyze_speaker_distribution(
                segments_with_speakers
            )
            
            return {
                "segments": segments_with_speakers,
                "speaker_statistics": speaker_stats,
                "total_speakers": speaker_stats.get("total_speakers", 0),
                "diarization_stats": self.speaker_diarizer.get_stats()
            }
            
        except Exception as e:
            raise Exception(f"í™”ì ë¶„ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_transcript(self, pipeline_results: Dict[str, Any]) -> Dict[str, Any]:
        """íšŒì˜ë¡ í›„ì²˜ë¦¬"""
        try:
            stt_result = pipeline_results.get("stt", {})
            diarization_result = pipeline_results.get("diarization", {})
            
            # í™”ì ë¶„ë¦¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ STT ê²°ê³¼ë§Œ ì‚¬ìš©
            if not diarization_result.get("skipped", False):
                segments = diarization_result.get("segments", [])
            else:
                segments = stt_result.get("segments", [])
            
            # íšŒì˜ë¡ ë©”íƒ€ë°ì´í„° ìƒì„±
            transcript = {
                "segments": segments,
                "metadata": {
                    "total_duration": stt_result.get("duration", 0.0),
                    "total_segments": len(segments),
                    "speakers_detected": diarization_result.get("total_speakers", 1),
                    "average_confidence": stt_result.get("confidence", 0.0),
                    "language": stt_result.get("language", "ko"),
                    "processing_timestamp": datetime.utcnow().isoformat()
                },
                "full_text": self._generate_full_text(segments),
                "speaker_summary": self._generate_speaker_summary(segments)
            }
            
            return transcript
            
        except Exception as e:
            raise Exception(f"íšŒì˜ë¡ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_agents(self, transcript: Dict[str, Any], agent_config: Dict[str, bool]) -> Dict[str, Any]:
        """ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„"""
        if not self.agent_orchestrator:
            logger.warning("ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return self._create_fallback_agent_results(transcript)
        
        try:
            # ì—ì´ì „íŠ¸ë³„ í™œì„±í™” ìƒíƒœì— ë”°ë¼ ë¶„ì„ ì‹¤í–‰
            agent_results = {}
            
            meeting_data = {
                "transcript": transcript.get("full_text", ""),
                "speakers": transcript.get("speakers", []),
                "timeline": transcript.get("segments", []),
                "metadata": transcript.get("metadata", {}),
                "content": transcript.get("full_text", "")
            }
            
            logger.info(f"ì—ì´ì „íŠ¸ ë¶„ì„ ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: í…ìŠ¤íŠ¸ {len(meeting_data['transcript'])}ì, ì„¸ê·¸ë¨¼íŠ¸ {len(meeting_data['timeline'])}ê°œ")
            
            # ê° ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰ (ì‹¤ì œë¡œëŠ” ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥)
            if agent_config.get("agenda_miner", True):
                logger.info("AgendaMiner ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["agendas"] = await self.agent_orchestrator.agenda_miner.analyze(
                        meeting_data
                    )
                    logger.info("AgendaMiner ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"AgendaMiner ì‹¤íŒ¨: {str(e)}")
                    agent_results["agendas"] = {"error": str(e), "agendas": []}
            
            if agent_config.get("claim_checker", True):
                logger.info("ClaimChecker ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["claims"] = await self.agent_orchestrator.claim_checker.analyze(
                        meeting_data
                    )
                    logger.info("ClaimChecker ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"ClaimChecker ì‹¤íŒ¨: {str(e)}")
                    agent_results["claims"] = {"error": str(e), "claims": []}
            
            if agent_config.get("counter_arguer", True):
                logger.info("CounterArguer ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["counter_arguments"] = await self.agent_orchestrator.counter_arguer.analyze(
                        meeting_data
                    )
                    logger.info("CounterArguer ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"CounterArguer ì‹¤íŒ¨: {str(e)}")
                    agent_results["counter_arguments"] = {"error": str(e), "counter_arguments": []}
            
            if agent_config.get("evidence_hunter", True):
                logger.info("EvidenceHunter ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["evidence"] = await self.agent_orchestrator.evidence_hunter.search_and_verify(
                        meeting_data["content"], meeting_data
                    )
                    logger.info("EvidenceHunter ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"EvidenceHunter ì‹¤íŒ¨: {str(e)}")
                    agent_results["evidence"] = {"error": str(e), "evidence_found": []}
            
            if agent_config.get("summarizer", True):
                logger.info("Summarizer ì‹¤í–‰ ì¤‘...")
                try:
                    agent_results["summary"] = await self.agent_orchestrator.summarizer.generate_report(
                        agent_results
                    )
                    logger.info("Summarizer ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"Summarizer ì‹¤íŒ¨: {str(e)}")
                    agent_results["summary"] = {"error": str(e), "action_items": [], "executive_summary": {}}
            
            logger.info(f"ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ. ê²°ê³¼ í‚¤: {list(agent_results.keys())}")
            return agent_results
            
        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ ë¶„ì„ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì—ì´ì „íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def _generate_report(self, pipeline_results: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        try:
            transcript = pipeline_results.get("transcript", {})
            agent_results = pipeline_results.get("agent_analysis", {})
            
            logger.info(f"ë³´ê³ ì„œ ìƒì„± - ì…ë ¥ ì²´í¬:")
            logger.info(f"  - transcript í‚¤: {list(transcript.keys()) if transcript else 'None'}")
            logger.info(f"  - agent_results í‚¤: {list(agent_results.keys()) if agent_results else 'None'}")
            
            # ê° ë‹¨ê³„ë³„ ë°ì´í„° ì¶”ì¶œ
            meeting_overview = self._generate_meeting_overview(transcript)
            logger.debug(f"meeting_overview: {meeting_overview}")
            
            key_findings = self._extract_key_findings(agent_results)
            logger.debug(f"key_findings: {len(key_findings)}ê°œ")
            
            action_items = self._extract_action_items(agent_results)
            logger.debug(f"action_items: {len(action_items)}ê°œ")
            
            recommendations = self._generate_recommendations(agent_results)
            logger.debug(f"recommendations: {len(recommendations)}ê°œ")
            
            report = {
                "executive_summary": {
                    "meeting_overview": meeting_overview,
                    "key_findings": key_findings,
                    "action_items": action_items,
                    "recommendations": recommendations
                },
                "detailed_analysis": {
                    "transcript_analysis": transcript.get("metadata", {}),
                    "speaker_analysis": transcript.get("speaker_summary", {}),
                    "content_analysis": agent_results
                },
                "technical_details": {
                    "processing_pipeline": {
                        "stt_engine": pipeline_results.get("stt", {}).get("engine_used"),
                        "diarization_enabled": not pipeline_results.get("diarization", {}).get("skipped", True),
                        "agents_used": list(agent_results.keys()) if agent_results else []
                    },
                    "quality_metrics": {
                        "stt_confidence": pipeline_results.get("stt", {}).get("confidence", 0.0),
                        "speakers_detected": transcript.get("metadata", {}).get("speakers_detected", 1),
                        "processing_time": None  # TODO: ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
                    }
                },
                "generated_at": datetime.utcnow().isoformat(),
                "format_version": "1.0"
            }
            
            logger.info("ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            logger.debug(f"ìµœì¢… ë³´ê³ ì„œ í‚¤: {list(report.keys())}")
            return report
            
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ ìƒì„¸: {str(e)}")
            logger.exception("ë³´ê³ ì„œ ìƒì„± ì˜ˆì™¸ ìƒì„¸:")
            raise Exception(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    async def _store_results(self, job_id: str, results: Dict[str, Any]) -> Dict[str, Any]:
        """ê²°ê³¼ ì €ì¥ - ì§ì ‘ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        print(f"ğŸ”„ _store_results í˜¸ì¶œë¨: job_id={job_id}")
        logger.info(f"ğŸ”„ _store_results í˜¸ì¶œë¨: job_id={job_id}")
        
        if not self.db_engine:
            print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ì´ ì—†ìŠµë‹ˆë‹¤")
            logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {"saved": False, "error": "ë°ì´í„°ë² ì´ìŠ¤ ì—”ì§„ì´ ì—†ìŒ"}
            
        try:
            # Import database models inside function
            try:
                from db.models import get_session, MeetingReport
            except ImportError as e:
                logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return {"saved": False, "error": "ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ import ì‹¤íŒ¨"}
            
            job = self.pipeline_jobs.get(job_id, {})
            
            # ì„¸ì…˜ ìƒì„±
            session = get_session(self.db_engine)
            
            try:
                # ê¸°ì¡´ ë³´ê³ ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
                existing_report = session.query(MeetingReport).filter_by(job_id=job_id).first()
                
                if existing_report:
                    # ê¸°ì¡´ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸
                    meeting_report = existing_report
                else:
                    # ìƒˆ ë³´ê³ ì„œ ìƒì„±
                    meeting_report = MeetingReport(job_id=job_id)
                    session.add(meeting_report)
                
                # ë³´ê³ ì„œ í•„ë“œ ì—…ë°ì´íŠ¸
                meeting_report.title = job.get("title", f"Meeting_{job_id[:8]}")
                meeting_report.original_filename = job.get("original_filename", "unknown.wav")
                meeting_report.file_size = job.get("file_size", 0)
                meeting_report.duration_seconds = results.get("stt", {}).get("duration", 0)
                meeting_report.num_speakers = len(results.get("diarization", {}).get("speakers", []))
                meeting_report.raw_results = results
                meeting_report.executive_summary = results.get("final_report", {}).get("executive_summary", {})
                meeting_report.agendas = results.get("agent_analysis", {}).get("agendas", {})
                meeting_report.claims = results.get("agent_analysis", {}).get("claims", {})
                meeting_report.counter_arguments = results.get("agent_analysis", {}).get("counter_arguments", {})
                meeting_report.evidence = results.get("agent_analysis", {}).get("evidence", {})
                meeting_report.final_report = results.get("final_report", {})
                meeting_report.status = "completed"
                meeting_report.progress = 100
                meeting_report.current_stage = "completed"
                meeting_report.completed_at = datetime.now()
                meeting_report.updated_at = datetime.now()
                
                session.commit()
                
                logger.info(f"âœ… ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {job_id}")
                return {
                    "saved": True,
                    "report_id": meeting_report.id,
                    "job_id": job_id
                }
                
            finally:
                session.close()
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"saved": False, "error": str(e)}
    
    def _generate_full_text(self, segments: List[Dict[str, Any]]) -> str:
        """ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ìƒì„±"""
        return " ".join([
            seg.get("text", "") for seg in segments 
            if seg.get("text", "").strip()
        ])
    
    def _generate_speaker_summary(self, segments: List[Dict[str, Any]]) -> Dict[str, Any]:
        """í™”ìë³„ ìš”ì•½ ìƒì„±"""
        speaker_data = {}
        
        for seg in segments:
            speaker = seg.get("speaker", "Unknown")
            if speaker not in speaker_data:
                speaker_data[speaker] = {
                    "utterance_count": 0,
                    "total_words": 0,
                    "total_duration": 0.0
                }
            
            speaker_data[speaker]["utterance_count"] += 1
            speaker_data[speaker]["total_words"] += len(seg.get("text", "").split())
            speaker_data[speaker]["total_duration"] += seg.get("duration", 0.0)
        
        return speaker_data
    
    def _generate_meeting_overview(self, transcript: Dict[str, Any]) -> str:
        """íšŒì˜ ê°œìš” ìƒì„±"""
        metadata = transcript.get("metadata", {})
        duration = metadata.get("total_duration", 0)
        speakers = metadata.get("speakers_detected", 1)
        
        return f"ì´ {duration:.1f}ì´ˆ ê¸¸ì´ì˜ íšŒì˜ì—ì„œ {speakers}ëª…ì˜ í™”ìê°€ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤."
    
    def _extract_key_findings(self, agent_results: Dict[str, Any]) -> List[str]:
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ì¶”ì¶œ"""
        findings = []
        
        if "agendas" in agent_results:
            agendas = agent_results["agendas"].get("agendas", [])
            findings.extend([f"ì£¼ìš” ì•ˆê±´: {agenda}" for agenda in agendas[:3]])
        
        if "claims" in agent_results:
            claims = agent_results["claims"].get("verified_claims", [])
            findings.extend([f"ê²€ì¦ëœ ì£¼ì¥: {claim}" for claim in claims[:2]])
        
        return findings or ["ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."]
    
    def _extract_action_items(self, agent_results: Dict[str, Any]) -> List[str]:
        """ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ"""
        if "summary" in agent_results:
            return agent_results["summary"].get("action_items", [])
        return ["ì•¡ì…˜ ì•„ì´í…œì´ ì‹ë³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
    
    def _generate_recommendations(self, agent_results: Dict[str, Any]) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if "counter_arguments" in agent_results:
            counter_args = agent_results["counter_arguments"].get("counter_arguments", [])
            if counter_args:
                recommendations.append("ì œì‹œëœ ë°˜ë°• ì˜ê²¬ë“¤ì„ ê²€í† í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        if "evidence" in agent_results:
            evidence = agent_results["evidence"].get("evidence_found", [])
            if evidence:
                recommendations.append("ì¶”ê°€ ì¦ê±° ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ì˜ì‚¬ê²°ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        return recommendations or ["íŠ¹ë³„í•œ ê¶Œì¥ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."]
    
    async def _update_progress(self, job_id: str, stage: str, progress: int):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        job = self.pipeline_jobs[job_id]
        job["current_stage"] = stage
        job["progress"] = progress
        
        # ì½œë°± í˜¸ì¶œ
        if job.get("progress_callback"):
            await job["progress_callback"](job_id, stage, progress, None)
    
    def get_job_status(self, job_id: str) -> Optional[Dict[str, Any]]:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        return self.pipeline_jobs.get(job_id)
    
    def get_job_results(self, job_id: str) -> Optional[Dict[str, Any]]:
        """ì‘ì—… ê²°ê³¼ ì¡°íšŒ"""
        job = self.pipeline_jobs.get(job_id)
        return job.get("results") if job else None
    
    def get_estimated_remaining_time(self, job_id: str) -> Optional[int]:
        """ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)"""
        job = self.pipeline_jobs.get(job_id)
        if not job:
            return None
        
        progress = job.get("progress", 0)
        if progress <= 0:
            return None
        
        # ì‹œì‘ ì‹œê°„ë¶€í„° í˜„ì¬ê¹Œì§€ ê²½ê³¼ ì‹œê°„ ê³„ì‚°
        started_at = job.get("started_at")
        if not started_at:
            return None
        
        try:
            start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
            elapsed_seconds = (datetime.utcnow() - start_time.replace(tzinfo=None)).total_seconds()
            
            # ì§„í–‰ë¥  ê¸°ë°˜ìœ¼ë¡œ ì˜ˆìƒ ì´ ì‹œê°„ ê³„ì‚°
            if progress > 0:
                estimated_total_time = elapsed_seconds / (progress / 100)
                remaining_time = estimated_total_time - elapsed_seconds
                return max(0, int(remaining_time))
        except:
            pass
        
        return None
    
    def cancel_job(self, job_id: str) -> bool:
        """ì‘ì—… ì·¨ì†Œ"""
        if job_id in self.pipeline_jobs:
            job = self.pipeline_jobs[job_id]
            if job["status"] in ["running", "initializing"]:
                job["status"] = "cancelled"
                job["completed_at"] = datetime.utcnow().isoformat()
                return True
        return False
    
    def cleanup_completed_jobs(self, max_age_hours: int = 24):
        """ì™„ë£Œëœ ì‘ì—… ì •ë¦¬"""
        current_time = datetime.utcnow()
        jobs_to_remove = []
        
        for job_id, job in self.pipeline_jobs.items():
            if job["status"] in ["completed", "failed", "cancelled"]:
                completed_at = datetime.fromisoformat(job["completed_at"])
                age_hours = (current_time - completed_at).total_seconds() / 3600
                
                if age_hours > max_age_hours:
                    jobs_to_remove.append(job_id)
        
        for job_id in jobs_to_remove:
            del self.pipeline_jobs[job_id]
        
        return len(jobs_to_remove)
    
    def _create_fallback_agent_results(self, transcript: Dict[str, Any]) -> Dict[str, Any]:
        """LLM ì—†ì´ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
        logger.info("ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
        
        full_text = transcript.get("full_text", "")
        segments = transcript.get("segments", [])
        speakers = transcript.get("speaker_summary", {})
        
        # ê¸°ë³¸ ì•„ì  ë‹¤
        basic_agenda = {
            "id": 1,
            "title": "íšŒì˜ ì£¼ìš” ë‚´ìš©",
            "description": f"ì´ {len(full_text)}ìì˜ íšŒì˜ë¡ì´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "category": "discussion",
            "priority": "medium",
            "related_topics": [],
            "outcomes": [],
            "action_items": [],
            "discussion_points": ["íšŒì˜ ë‚´ìš© ìš”ì•½ì´ í•„ìš”í•©ë‹ˆë‹¤."]
        }
        
        # ê¸°ë³¸ ì£¼ì¥ ë¶„ì„
        basic_claim = {
            "id": 1,
            "speaker": "ì•Œ ìˆ˜ ì—†ìŒ",
            "claim": "ì£¼ìš” ë…¼ì˜ ì‚¬í•­ì´ ìˆì—ˆìŠµë‹ˆë‹¤.",
            "type": "opinion",
            "confidence_level": "low",
            "evidence": [],
            "context": "ì „ì²´ íšŒì˜ ë§¥ë½",
            "implications": [],
            "related_claims": [],
            "time_reference": "íšŒì˜ ì „ë°˜"
        }
        
        return {
            "agendas": {
                "agendas": [basic_agenda],
                "confidence": 0.3,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "claims": {
                "claims": [basic_claim],
                "confidence": 0.3,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "counter_arguments": {
                "counter_arguments": [],
                "confidence": 0.0,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "evidence": {
                "evidence_found": [],
                "confidence": 0.0,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            },
            "summary": {
                "executive_summary": {
                    "overview": f"ì´ {len(segments)}ê°œ ë°œí™”ê°€ í¬í•¨ëœ íšŒì˜ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "participants": len(speakers),
                    "duration": transcript.get("metadata", {}).get("total_duration", 0)
                },
                "action_items": [],
                "key_decisions": [],
                "next_steps": [],
                "confidence": 0.3,
                "processing_note": "LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ê²°ê³¼ ìƒì„±ë¨"
            }
        }