"""
íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ (MeetingAnalysisPipeline)

ì˜¤ë””ì˜¤ â†’ STT â†’ í™”ìë¶„ë¦¬ â†’ ë©€í‹°ì—ì´ì „íŠ¸ ë¶„ì„ â†’ ë³´ê³ ì„œ ìƒì„±ì˜ 
ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime
from pathlib import Path
import uuid

logger = logging.getLogger(__name__)

# ì§€ì—° importë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
SpeakerAnalyzer = None



class MeetingAnalysisPipeline:
    """íšŒì˜ ë¶„ì„ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, 
                 stt_manager=None,
                 speaker_diarizer=None, 
                 llm_client=None,
                 chroma_manager=None,
                 embedding_client=None,
                 db_engine=None):
        self.stt_manager = stt_manager
        self.speaker_diarizer = speaker_diarizer
        self.llm_client = llm_client  # agent_orchestrator ëŒ€ì‹  llm_client ì§ì ‘ ì‚¬ìš©
        self.chroma_manager = chroma_manager  # ChromaDB ë§¤ë‹ˆì € ì§ì ‘ ì „ë‹¬
        self.embedding_client = embedding_client
        self.db_engine = db_engine
        
        # íŒŒì´í”„ë¼ì¸ ìƒíƒœ ê´€ë¦¬
        self.pipeline_jobs = {}
        
        # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì •ì˜
        self.pipeline_stages = [
            "file_validation",
            "stt_processing", 
            "speaker_diarization",
            "transcript_processing",
            "speaker_analysis",  # ìƒˆë¡œìš´ í™”ì ì¤‘ì‹¬ ë¶„ì„ ë‹¨ê³„
            "simple_analysis",  # ë‹¨ìˆœ 2ë‹¨ê³„ ë¶„ì„
            "report_generation",
            "result_storage"
        ]
        
        # ê° ë‹¨ê³„ë³„ ê°€ì¤‘ì¹˜ (ì§„í–‰ë¥  ê³„ì‚°ìš©)
        self.stage_weights = {
            "file_validation": 5,
            "stt_processing": 20,
            "speaker_diarization": 10,
            "transcript_processing": 8,
            "speaker_analysis": 12,  # ìƒˆë¡œìš´ ë‹¨ê³„
            "simple_analysis": 30,  # ë‹¨ìˆœ 2ë‹¨ê³„ ë¶„ì„
            "report_generation": 12,
            "result_storage": 3
        }
        
        # í™”ì ë¶„ì„ê¸° ì´ˆê¸°í™” (ì§€ì—° ë¡œë”©)
        self.speaker_analyzer = None
    
    async def start_analysis(self, 
                           audio_file_path: str,
                           options: Optional[Dict[str, Any]] = None,
                           progress_callback: Optional[Callable] = None) -> str:
        """íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        
        # ì‘ì—… ID ìƒì„±
        job_id = f"pipeline_{uuid.uuid4().hex[:8]}"
        
        # ê¸°ë³¸ ì˜µì…˜ ì„¤ì •
        default_options = {
            "stt_engine": "returnzero",
            "language": "ko", 
            "enable_diarization": True,
            "enable_agents": True,
            "agent_config": {
                "agenda_miner": True,
                "claim_checker": True,
                "counter_arguer": True,
                "evidence_hunter": True,
                "summarizer": True
            }
        }
        pipeline_options = {**default_options, **(options or {})}
        
        # ì‘ì—… ìƒíƒœ ì´ˆê¸°í™”
        self.pipeline_jobs[job_id] = {
            "status": "initializing",
            "audio_file": audio_file_path,
            "options": pipeline_options,
            "progress": 0,
            "current_stage": None,
            "started_at": datetime.utcnow().isoformat(),
            "completed_at": None,
            "error": None,
            "results": {},
            "progress_callback": progress_callback,
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            "title": pipeline_options.get("title", f"Meeting_{job_id[:8]}"),
            "original_filename": pipeline_options.get("original_filename", "unknown.wav"),
            "file_size": pipeline_options.get("file_size", 0)
        }
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)
        logger.info(f"=== íŒŒì´í”„ë¼ì¸ ì‹œì‘: {job_id} ===")
        logger.info(f"ì˜¤ë””ì˜¤ íŒŒì¼: {audio_file_path}")
        logger.info(f"ì˜µì…˜: {pipeline_options}")
        
        task = asyncio.create_task(self._execute_pipeline(job_id))
        
        # íƒœìŠ¤í¬ ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± ì¶”ê°€
        def task_done_callback(task):
            if task.exception():
                logger.error(f"íŒŒì´í”„ë¼ì¸ íƒœìŠ¤í¬ ì˜¤ë¥˜ ({job_id}): {task.exception()}")
                import traceback
                logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exception(type(task.exception()), task.exception(), task.exception().__traceback__)}")
                
                # ì‘ì—… ìƒíƒœë¥¼ ì‹¤íŒ¨ë¡œ ì—…ë°ì´íŠ¸
                if job_id in self.pipeline_jobs:
                    self.pipeline_jobs[job_id]["status"] = "failed"
                    self.pipeline_jobs[job_id]["error"] = str(task.exception())
                    self.pipeline_jobs[job_id]["completed_at"] = datetime.utcnow().isoformat()
            else:
                logger.info(f"íŒŒì´í”„ë¼ì¸ íƒœìŠ¤í¬ ì™„ë£Œ ({job_id})")
        
        task.add_done_callback(task_done_callback)
        
        logger.info(f"íšŒì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {job_id}")
        return job_id
    
    async def _execute_pipeline(self, job_id: str):
        """ë‹¨ìˆœí™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        logger.info(f"íŒŒì´í”„ë¼ì¸ ì‹œì‘: {job_id}")
        
        job = self.pipeline_jobs[job_id]
        
        try:
            job["status"] = "running"
            
            # 1. íŒŒì¼ ê²€ì¦ (5%)
            await self._update_progress(job_id, "file_validation", 5)
            validation_result = await self._validate_audio_file(job["audio_file"])
            if not validation_result["valid"]:
                raise Exception(f"íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {validation_result['error']}")
            
            # 2. STT ì²˜ë¦¬ (50%)
            await self._update_progress(job_id, "stt_processing", 20)
            stt_result = await self._process_stt(job["audio_file"], job["options"])
            await self._update_progress(job_id, "stt_processing", 50)
            
            # 3. ê°„ë‹¨í•œ ì „ì‚¬ë³¸ êµ¬ì„± (60%)
            await self._update_progress(job_id, "transcript_processing", 60)
            transcript = {
                "full_text": stt_result.get("full_text", ""),  # STT ê²°ê³¼ ì§ì ‘ ì‚¬ìš©
                "segments": stt_result.get("segments", []),
                "metadata": {
                    "total_duration": stt_result.get("duration", 0.0),
                    "total_segments": len(stt_result.get("segments", [])),
                    "language": stt_result.get("language", "ko"),
                    "confidence": stt_result.get("confidence", 0.0)
                }
            }
            
            logger.info(f"ì „ì‚¬ ì™„ë£Œ: {len(transcript['full_text'])}ì, {len(transcript['segments'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
            
            # 4. í†µí•© ë¶„ì„ (85%) - ê°„ì†Œí™”ëœ 2ë‹¨ê³„ ë¶„ì„
            agent_results = {"skipped": True}
            if job["options"]["enable_agents"]:
                await self._update_progress(job_id, "simple_analysis", 65)
                logger.info("ğŸ” ë‹¨ìˆœ íšŒì˜ ë¶„ì„ ì‹œì‘ (2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤: ìš”ì•½ + RAG ë¶„ì„)")
                
                try:
                    # ë‹¨ìˆœ ë¶„ì„ê¸° ì´ˆê¸°í™”
                    simple_analyzer = self._get_simple_analyzer()
                    
                    if simple_analyzer:
                        await self._update_progress(job_id, "simple_analysis", 70)
                        logger.info(f"ë¶„ì„ ì…ë ¥: í…ìŠ¤íŠ¸ {len(transcript['full_text'])}ì, ì„¸ê·¸ë¨¼íŠ¸ {len(transcript['segments'])}ê°œ")
                        
                        # ë‹¨ìˆœ ë¶„ì„ ì‹¤í–‰
                        agent_results = await simple_analyzer.analyze_meeting(
                            transcript_text=transcript["full_text"],
                            segments=transcript["segments"]
                        )
                        await self._update_progress(job_id, "simple_analysis", 85)
                        
                        # ë¶„ì„ ê²°ê³¼ ë¡œê¹…
                        if agent_results:
                            logger.info(f"âœ… í†µí•© ë¶„ì„ ì™„ë£Œ: ì‹ ë¢°ë„ {agent_results.get('confidence', 0):.2f}")
                            
                            # ì£¼ìš” ê²°ê³¼ ìš”ì•½ ë¡œê¹…
                            exec_summary = agent_results.get("executive_summary", {})
                            agenda_count = len(exec_summary.get("agenda_items", []))
                            action_count = len(exec_summary.get("action_items", []))
                            insights_count = len(exec_summary.get("insights", []))
                            
                            logger.info(f"ğŸ“‹ ì‹ë³„ëœ ì•„ì  ë‹¤: {agenda_count}ê°œ")
                            logger.info(f"ğŸ“ ì•¡ì…˜ ì•„ì´í…œ: {action_count}ê°œ")
                            logger.info(f"ğŸ’¡ ì¸ì‚¬ì´íŠ¸: {insights_count}ê°œ")
                            
                            if agent_results.get("related_context"):
                                context_count = len(agent_results["related_context"])
                                logger.info(f"ğŸ”— ê´€ë ¨ ë¬¸ì„œ: {context_count}ê°œ")
                        else:
                            logger.warning("âš ï¸ í†µí•© ë¶„ì„ ê²°ê³¼ê°€ Noneì„")
                    else:
                        logger.warning("âš ï¸ í†µí•© ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŒ")
                        agent_results = self._create_simple_fallback_results(transcript)
                        
                except Exception as e:
                    logger.error(f"âŒ í†µí•© ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                    logger.error(f"ì—ëŸ¬ íƒ€ì…: {type(e)}")
                    import traceback
                    logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                    agent_results = self._create_simple_fallback_results(transcript)
                    await self._update_progress(job_id, "simple_analysis", 80)
                    logger.info("ğŸ”„ Fallback ê²°ê³¼ë¡œ ëŒ€ì²´ë¨")
            else:
                logger.info("â© ë¶„ì„ ë¹„í™œì„±í™”ë¨ - ê¸°ë³¸ ê²°ê³¼ ìƒì„±")
                agent_results = self._create_simple_fallback_results(transcript)
            
            # 5. ë³´ê³ ì„œ ìƒì„± (95%)
            await self._update_progress(job_id, "report_generation", 90)
            logger.info("ğŸ“Š ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì‹œì‘")
            report = await self._generate_simple_report(transcript, agent_results)
            
            if report:
                logger.info(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {type(report)} íƒ€ì…")
                if isinstance(report, dict):
                    logger.info(f"ë³´ê³ ì„œ í‚¤: {list(report.keys())}")
            else:
                logger.warning("âš ï¸ ë³´ê³ ì„œ ìƒì„± ê²°ê³¼ê°€ Noneì„")
            
            # 6. ê²°ê³¼ ì €ì¥ (100%)
            await self._update_progress(job_id, "result_storage", 95)
            job["results"] = {
                "stt": stt_result,
                "transcript": transcript,
                "agent_analysis": agent_results,
                "final_report": report
            }
            
            logger.info("ğŸ’¾ ìµœì¢… ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘")
            storage_result = await self._store_results(job_id, job["results"])
            
            if storage_result.get("saved"):
                logger.info(f"âœ… DB ì €ì¥ ì„±ê³µ: report_id={storage_result.get('report_id')}")
            else:
                logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {storage_result.get('error')}")
            
            # ì™„ë£Œ
            job["status"] = "completed"
            job["completed_at"] = datetime.utcnow().isoformat()
            await self._update_progress(job_id, "completed", 100)
            
            logger.info(f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {job_id}")
            
        except Exception as e:
            job["status"] = "failed"
            job["error"] = str(e)
            job["completed_at"] = datetime.utcnow().isoformat()
            logger.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {job_id} - {e}")
            
            if job.get("progress_callback"):
                await job["progress_callback"](job_id, "failed", 0, str(e))
    
    async def _validate_audio_file(self, file_path: str) -> Dict[str, Any]:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦"""
        try:
            path = Path(file_path)
            
            if not path.exists():
                return {"valid": False, "error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}
            
            if path.stat().st_size == 0:
                return {"valid": False, "error": "íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            valid_extensions = ['.wav', '.mp3', '.mp4', '.m4a', '.flac', '.ogg']
            if path.suffix.lower() not in valid_extensions:
                return {"valid": False, "error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {path.suffix}"}
            
            return {
                "valid": True,
                "file_size": path.stat().st_size,
                "file_format": path.suffix,
                "file_name": path.name
            }
            
        except Exception as e:
            return {"valid": False, "error": str(e)}
    
    async def _process_stt(self, file_path: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """STT ì²˜ë¦¬"""
        if not self.stt_manager:
            raise Exception("STT ë§¤ë‹ˆì €ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            result = self.stt_manager.transcribe(
                file_path, 
                options.get("stt_engine", "returnzero"),
                options.get("language", "ko")
            )
            
            return {
                "engine_used": options.get("stt_engine", "returnzero"),
                "language": options.get("language", "ko"),
                "segments": result.get("segments", []),
                "full_text": result.get("text", ""),
                "confidence": result.get("confidence", 0.0),
                "duration": result.get("duration", 0.0)
            }
            
        except Exception as e:
            raise Exception(f"STT ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_diarization(self, file_path: str, stt_segments: List[Dict]) -> Dict[str, Any]:
        """í™”ì ë¶„ë¦¬ ì²˜ë¦¬"""
        if not self.speaker_diarizer:
            raise Exception("í™”ì ë¶„ë¦¬ ì‹œìŠ¤í…œì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            segments_with_speakers = await self.speaker_diarizer.diarize_audio(
                file_path, stt_segments
            )
            
            speaker_stats = self.speaker_diarizer.analyze_speaker_distribution(
                segments_with_speakers
            )
            
            return {
                "segments": segments_with_speakers,
                "speaker_statistics": speaker_stats,
                "total_speakers": speaker_stats.get("total_speakers", 0),
                "diarization_stats": self.speaker_diarizer.get_stats()
            }
            
        except Exception as e:
            raise Exception(f"í™”ì ë¶„ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    async def _generate_simple_report(self, transcript: Dict[str, Any], agent_results: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ìˆœí™”ëœ ë³´ê³ ì„œ ìƒì„± - SimpleMeetingAnalyzer ì¶œë ¥ê³¼ ê¸°ì¡´ í•„ë“œ ë§¤í•‘"""
        try:
            full_text = transcript.get("full_text", "")
            metadata = transcript.get("metadata", {})
            
            # ê¸°ë³¸ í†µê³„
            duration = metadata.get("total_duration", 0)
            word_count = len(full_text.split()) if full_text else 0
            
            # SimpleMeetingAnalyzer ê²°ê³¼ë¥¼ ê¸°ì¡´ í•„ë“œ êµ¬ì¡°ì— ë§¤í•‘
            executive_summary = {}
            agendas = []
            claims = []
            evidence = []
            final_report_text = ""
            
            if agent_results and not agent_results.get("skipped"):
                # SimpleMeetingAnalyzer ì¶œë ¥ êµ¬ì¡° ë§¤í•‘
                executive_summary = {
                    "overview": agent_results.get("overview", "ë¶„ì„ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤."),
                    "key_points": agent_results.get("key_points", []),
                    "main_topics": agent_results.get("main_topics", []),
                    "decisions": agent_results.get("decisions", []),
                    "action_items": agent_results.get("action_items", []),
                    "insights": agent_results.get("insights", []),
                    "recommendations": agent_results.get("recommendations", []),
                    "processing_method": agent_results.get("processing_method", "simple_2step_analysis")
                }
                
                # ê¸°ì¡´ í•„ë“œì™€ ë§¤í•‘
                agendas = agent_results.get("main_topics", [])
                claims = agent_results.get("key_points", [])
                evidence = agent_results.get("insights", [])
                
                # ìµœì¢… ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ìƒì„±
                final_report_parts = []
                if agent_results.get("overview"):
                    final_report_parts.append(f"**ê°œìš”**: {agent_results['overview']}")
                if agent_results.get("key_points"):
                    final_report_parts.append(f"**í•µì‹¬ í¬ì¸íŠ¸**: {', '.join(agent_results['key_points'][:3])}")
                if agent_results.get("recommendations"):
                    final_report_parts.append(f"**ê¶Œì¥ì‚¬í•­**: {', '.join(agent_results['recommendations'][:3])}")
                
                final_report_text = "\n\n".join(final_report_parts) if final_report_parts else "ë¶„ì„ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
            
            report = {
                "title": "íšŒì˜ ë¶„ì„ ë³´ê³ ì„œ",
                "generated_at": datetime.utcnow().isoformat(),
                "summary": {
                    "duration_seconds": duration,
                    "word_count": word_count,
                    "character_count": len(full_text),
                    "language": metadata.get("language", "ko")
                },
                "transcript": full_text,
                "agent_analysis": agent_results,
                "executive_summary": executive_summary,
                "agendas": agendas,
                "claims": claims,
                "evidence": evidence,
                "final_report": final_report_text
            }
            
            return report
            
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "title": "íšŒì˜ ë¶„ì„ ë³´ê³ ì„œ (ì˜¤ë¥˜)",
                "generated_at": datetime.utcnow().isoformat(),
                "error": str(e),
                "transcript": transcript.get("full_text", ""),
                "executive_summary": {},
                "agendas": [],
                "claims": [],
                "evidence": [],
                "final_report": f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    
    
    
    async def _store_results(self, job_id: str, results: Dict[str, Any]) -> Dict[str, Any]:
        """ê²°ê³¼ ì €ì¥ - ë‹¨ìˆœí™”ëœ ë‚´ìš©ë§Œ ì €ì¥"""
        if not self.db_engine:
            return {"saved": False, "error": "DB ì—”ì§„ ì—†ìŒ"}
            
        try:
            # Import database models inside function
            try:
                from db.models import get_session, MeetingReport
            except ImportError as e:
                logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return {"saved": False, "error": "ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ import ì‹¤íŒ¨"}
            
            job = self.pipeline_jobs.get(job_id, {})
            
            # ì„¸ì…˜ ìƒì„±
            session = get_session(self.db_engine)
            
            try:
                # ê¸°ì¡´ ë³´ê³ ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
                existing_report = session.query(MeetingReport).filter_by(job_id=job_id).first()
                
                if existing_report:
                    # ê¸°ì¡´ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸
                    meeting_report = existing_report
                else:
                    # ìƒˆ ë³´ê³ ì„œ ìƒì„±
                    meeting_report = MeetingReport(job_id=job_id)
                    session.add(meeting_report)
                
                # ë³´ê³ ì„œ í•„ë“œ ì—…ë°ì´íŠ¸
                meeting_report.title = job.get("title", f"Meeting_{job_id[:8]}")
                meeting_report.original_filename = job.get("original_filename", "unknown.wav")
                meeting_report.file_size = job.get("file_size", 0)
                meeting_report.duration_seconds = results.get("stt", {}).get("duration", 0)
                meeting_report.num_speakers = len(results.get("diarization", {}).get("speakers", []))
                meeting_report.raw_results = results
                # SimpleMeetingAnalyzer ê²°ê³¼ë¥¼ ê¸°ì¡´ DB ìŠ¤í‚¤ë§ˆì— ë§¤í•‘
                final_report = results.get("final_report", {})
                agent_analysis = results.get("agent_analysis", {})
                
                meeting_report.executive_summary = final_report.get("executive_summary", {})
                meeting_report.agendas = final_report.get("agendas", [])  # main_topics ë§¤í•‘ë¨
                meeting_report.claims = final_report.get("claims", [])    # key_points ë§¤í•‘ë¨  
                meeting_report.counter_arguments = []  # SimpleMeetingAnalyzerì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                meeting_report.evidence = final_report.get("evidence", [])  # insights ë§¤í•‘ë¨
                meeting_report.final_report = results.get("final_report", {})
                meeting_report.status = "completed"
                meeting_report.progress = 100
                meeting_report.current_stage = "completed"
                meeting_report.completed_at = datetime.now()
                meeting_report.updated_at = datetime.now()
                
                session.commit()
                
                logger.info(f"âœ… ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {job_id}")
                return {
                    "saved": True,
                    "report_id": meeting_report.id,
                    "job_id": job_id
                }
                
            finally:
                session.close()
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"saved": False, "error": str(e)}
    
    async def _update_progress_in_db(self, job_id: str, stage: str, progress: int):
        """DBì— ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        if not self.db_engine:
            logger.warning("DB ì—”ì§„ì´ ì—†ì–´ì„œ ì§„í–‰ë¥ ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
            
        try:
            # Import database models inside function
            from db.models import get_session, MeetingReport
            
            job = self.pipeline_jobs.get(job_id, {})
            
            # ì„¸ì…˜ ìƒì„±
            session = get_session(self.db_engine)
            
            try:
                # ê¸°ì¡´ ë³´ê³ ì„œê°€ ìˆëŠ”ì§€ í™•ì¸
                existing_report = session.query(MeetingReport).filter_by(job_id=job_id).first()
                
                if existing_report:
                    # ê¸°ì¡´ ë³´ê³ ì„œ ì—…ë°ì´íŠ¸
                    meeting_report = existing_report
                else:
                    # ìƒˆ ë³´ê³ ì„œ ìƒì„±
                    meeting_report = MeetingReport(job_id=job_id)
                    session.add(meeting_report)
                    
                    # ì´ˆê¸° ë©”íƒ€ë°ì´í„° ì„¤ì •
                    meeting_report.title = job.get("title", f"Meeting_{job_id[:8]}")
                    meeting_report.original_filename = job.get("original_filename", "unknown.wav")
                    meeting_report.file_size = job.get("file_size", 0)
                
                # ì§„í–‰ë¥  ì •ë³´ ì—…ë°ì´íŠ¸
                meeting_report.status = "processing"
                meeting_report.progress = progress
                meeting_report.current_stage = stage
                meeting_report.updated_at = datetime.now()
                
                session.commit()
                logger.debug(f"âœ… DB ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì™„ë£Œ: {job_id} - {stage} ({progress}%)")
                
            finally:
                session.close()
            
        except Exception as e:
            logger.error(f"âŒ DB ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            # DB ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ íŒŒì´í”„ë¼ì¸ì€ ê³„ì† ì§„í–‰
    
    
    
    
    
    
    
    
    async def _update_progress(self, job_id: str, stage: str, progress: int):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ - ë©”ëª¨ë¦¬ì™€ DBì— ëª¨ë‘ ì €ì¥"""
        job = self.pipeline_jobs[job_id]
        job["current_stage"] = stage
        job["progress"] = progress
        
        logger.info(f"ğŸ“Š ì§„í–‰ë¥  ì—…ë°ì´íŠ¸: {job_id} - {stage} ({progress}%)")
        
        # DBì—ë„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì €ì¥
        await self._update_progress_in_db(job_id, stage, progress)
        
        # ì½œë°± í˜¸ì¶œ
        if job.get("progress_callback"):
            await job["progress_callback"](job_id, stage, progress, None)
    
    def get_job_status(self, job_id: str) -> Optional[Dict[str, Any]]:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        return self.pipeline_jobs.get(job_id)
    
    def get_job_results(self, job_id: str) -> Optional[Dict[str, Any]]:
        """ì‘ì—… ê²°ê³¼ ì¡°íšŒ"""
        job = self.pipeline_jobs.get(job_id)
        return job.get("results") if job else None
    
    def get_estimated_remaining_time(self, job_id: str) -> Optional[int]:
        """ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)"""
        job = self.pipeline_jobs.get(job_id)
        if not job:
            return None
        
        progress = job.get("progress", 0)
        if progress <= 0:
            return None
        
        # ì‹œì‘ ì‹œê°„ë¶€í„° í˜„ì¬ê¹Œì§€ ê²½ê³¼ ì‹œê°„ ê³„ì‚°
        started_at = job.get("started_at")
        if not started_at:
            return None
        
        try:
            start_time = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
            elapsed_seconds = (datetime.utcnow() - start_time.replace(tzinfo=None)).total_seconds()
            
            # ì§„í–‰ë¥  ê¸°ë°˜ìœ¼ë¡œ ì˜ˆìƒ ì´ ì‹œê°„ ê³„ì‚°
            if progress > 0:
                estimated_total_time = elapsed_seconds / (progress / 100)
                remaining_time = estimated_total_time - elapsed_seconds
                return max(0, int(remaining_time))
        except:
            pass
        
        return None
    
    def cancel_job(self, job_id: str) -> bool:
        """ì‘ì—… ì·¨ì†Œ"""
        if job_id in self.pipeline_jobs:
            job = self.pipeline_jobs[job_id]
            if job["status"] in ["running", "initializing"]:
                job["status"] = "cancelled"
                job["completed_at"] = datetime.utcnow().isoformat()
                return True
        return False
    
    def cleanup_completed_jobs(self, max_age_hours: int = 24):
        """ì™„ë£Œëœ ì‘ì—… ì •ë¦¬"""
        current_time = datetime.utcnow()
        jobs_to_remove = []
        
        for job_id, job in self.pipeline_jobs.items():
            if job["status"] in ["completed", "failed", "cancelled"]:
                completed_at = datetime.fromisoformat(job["completed_at"])
                age_hours = (current_time - completed_at).total_seconds() / 3600
                
                if age_hours > max_age_hours:
                    jobs_to_remove.append(job_id)
        
        for job_id in jobs_to_remove:
            del self.pipeline_jobs[job_id]
        
        return len(jobs_to_remove)
    
    def _get_simple_analyzer(self):
        """ë‹¨ìˆœ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        try:
            from agents.simple_analyzer import SimpleMeetingAnalyzer
            
            # LLM í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì‚¬ìš©
            llm_client = self.llm_client
            
            # ChromaDB ë§¤ë‹ˆì € ì§ì ‘ ì‚¬ìš©
            chroma_manager = self.chroma_manager
            
            analyzer = SimpleMeetingAnalyzer(
                llm_client=llm_client,
                chroma_manager=chroma_manager,
                embedding_client=self.embedding_client
            )
            
            logger.info(f"âœ… ë‹¨ìˆœ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (LLM: {'ìˆìŒ' if llm_client else 'ì—†ìŒ'}, ChromaDB: {'ìˆìŒ' if chroma_manager else 'ì—†ìŒ'})")
            return analyzer
            
        except Exception as e:
            logger.error(f"âŒ ë‹¨ìˆœ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _create_simple_fallback_results(self, transcript: Dict[str, Any]) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ - ê°œì„ ëœ ë²„ì „"""
        full_text = transcript.get("full_text", "")
        segments = transcript.get("segments", [])
        
        # ê¸°ë³¸ í†µê³„ ë¶„ì„
        word_count = len(full_text.split()) if full_text else 0
        char_count = len(full_text)
        segment_count = len(segments)
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê³µë°±/íŠ¹ìˆ˜ë¬¸ìë¡œ ë¶„ë¦¬ëœ ë‹¨ì–´ ì¤‘ ê¸¸ì´ 3 ì´ìƒ)
        import re
        words = re.findall(r'\b\w{3,}\b', full_text) if full_text else []
        unique_words = list(set(words))[:10]  # ìƒìœ„ 10ê°œ ê³ ìœ  ë‹¨ì–´
        
        return {
            "executive_summary": {
                "overview": f"ì´ {char_count}ì, {word_count}ë‹¨ì–´ë¡œ êµ¬ì„±ëœ íšŒì˜ ë‚´ìš©ì„ ê¸°ë³¸ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
                "key_points": [
                    f"íšŒì˜ ê¸¸ì´: {char_count}ì ({word_count}ë‹¨ì–´)",
                    f"ë°œí™” ì„¸ê·¸ë¨¼íŠ¸: {segment_count}ê°œ",
                    f"ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(unique_words[:5])}" if unique_words else "í‚¤ì›Œë“œ ì—†ìŒ"
                ]
            },
            "detailed_analysis": {
                "findings": [
                    f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {char_count}ì",
                    f"ë‹¨ì–´ ìˆ˜: {word_count}ê°œ",
                    f"ë°œí™” ì„¸ê·¸ë¨¼íŠ¸: {segment_count}ê°œ"
                ],
                "insights": [
                    "AI ì—ì´ì „íŠ¸ ë¶„ì„ì€ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜ ê¸°ë³¸ í†µê³„ ë¶„ì„ì€ ì™„ë£Œë¨",
                    "ì¶”ê°€ ë¶„ì„ì„ ì›í•  ê²½ìš° ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë” ìƒì„¸í•œ íšŒì˜ë¡ ì œê³µ ê¶Œì¥"
                ]
            },
            "detailed_results": {
                "agenda_analysis": {
                    "agendas": [],
                    "processing_note": "ì—ì´ì „íŠ¸ ë¶„ì„ ì‹¤íŒ¨ë¡œ ì•„ì  ë‹¤ ì¶”ì¶œë˜ì§€ ì•ŠìŒ"
                },
                "claim_analysis": {
                    "claims": [],
                    "processing_note": "ì—ì´ì „íŠ¸ ë¶„ì„ ì‹¤íŒ¨ë¡œ ì£¼ì¥ ë¶„ì„ë˜ì§€ ì•ŠìŒ"
                }
            },
            "confidence": 0.4,
            "processing_method": "fallback_analysis",
            "processing_note": "ì—ì´ì „íŠ¸ ë¶„ì„ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ ê²°ê³¼ ìƒì„±"
        }