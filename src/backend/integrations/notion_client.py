"""
Notion API í´ë¼ì´ì–¸íŠ¸
Notion í˜ì´ì§€ ë° ë°ì´í„°ë² ì´ìŠ¤ì™€ì˜ í†µí•©ì„ ë‹´ë‹¹
"""

import os
import asyncio
import aiohttp
from typing import List, Dict, Any, Optional
from langchain_core.documents import Document


class NotionClient:
    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("NOTION_API_KEY")
        self.base_url = "https://api.notion.com/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Notion-Version": "2022-06-28",
            "Content-Type": "application/json"
        }

    def get_page_ids_from_env(self) -> List[str]:
        """í™˜ê²½ ë³€ìˆ˜ì—ì„œ ëª¨ë“  Notion í˜ì´ì§€ IDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        page_ids = []
        i = 1
        while True:
            page_id = os.getenv(f"NOTION_PAGE_ID_{i}")
            if page_id:
                # í˜ì´ì§€ ID ì •ê·œí™”
                if '-' in page_id:
                    parts = page_id.split('-')
                    if len(parts) > 1 and len(parts[-1]) >= 32:
                        uuid_part = ''.join(parts[1:])
                        page_id = uuid_part.replace('-', '')
                
                if len(page_id) == 32 and page_id.replace('-', '').isalnum():
                    page_ids.append(page_id)
                i += 1
            else:
                break
        return page_ids

    async def get_block_children(self, session: aiohttp.ClientSession, block_id: str, timeout: int = 30) -> List[Dict[str, Any]]:
        """ë¸”ë¡ì˜ í•˜ìœ„ ë¸”ë¡ë“¤ì„ ë¹„ë™ê¸°ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        all_blocks = []
        start_cursor = None
        
        while True:
            url = f"{self.base_url}/blocks/{block_id}/children"
            params = {"page_size": 100}
            if start_cursor:
                params["start_cursor"] = start_cursor
            
            try:
                async with session.get(url, headers=self.headers, params=params, timeout=timeout) as response:
                    if response.status != 200:
                        break
                    
                    data = await response.json()
                    blocks = data.get("results", [])
                    all_blocks.extend(blocks)
                    
                    if not data.get("has_more"):
                        break
                    
                    start_cursor = data.get("next_cursor")
            
            except asyncio.TimeoutError:
                break
            
            await asyncio.sleep(0.05)  # Rate limit protection
        
        return all_blocks

    def extract_rich_text(self, rich_text_list: List[Dict[str, Any]]) -> str:
        """Rich text ë°°ì—´ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not rich_text_list:
            return ""
        
        text_parts = []
        for rt in rich_text_list:
            text = rt.get("plain_text", "")
            text_parts.append(text)
        
        return "".join(text_parts)

    def process_block_content(self, block: Dict[str, Any]) -> List[str]:
        """ë¸”ë¡ì˜ ë‚´ìš©ì„ ì²˜ë¦¬í•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        content_parts = []
        block_type = block.get("type")
        block_data = block.get(block_type, {})
        
        # í…ìŠ¤íŠ¸ ë¸”ë¡ ì²˜ë¦¬
        text_blocks = ["paragraph", "heading_1", "heading_2", "heading_3", 
                      "bulleted_list_item", "numbered_list_item", "quote", "code"]
        
        if block_type in text_blocks and block_data.get("rich_text"):
            text = self.extract_rich_text(block_data["rich_text"])
            if text.strip():
                if block_type.startswith("heading"):
                    level = block_type.split("_")[1]
                    text = "#" * int(level) + " " + text
                elif block_type == "bulleted_list_item":
                    text = "â€¢ " + text
                elif block_type == "numbered_list_item":
                    text = "1. " + text
                elif block_type == "quote":
                    text = "> " + text
                elif block_type == "code":
                    text = f"```\\n{text}\\n```"
                
                content_parts.append(text)
        
        return content_parts

    async def get_page_metadata(self, session: aiohttp.ClientSession, page_id: str) -> Dict[str, Any]:
        """í˜ì´ì§€ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            async with session.get(
                f"{self.base_url}/pages/{page_id}",
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    page_data = await response.json()
                    return {
                        'last_edited_time': page_data.get('last_edited_time'),
                        'created_time': page_data.get('created_time'),
                        'properties': page_data.get('properties', {})
                    }
        except Exception as e:
            print(f"âš ï¸ í˜ì´ì§€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ {page_id}: {e}")
        return {}

    async def load_page_content(self, session: aiohttp.ClientSession, page_id: str) -> Document:
        """Notion í˜ì´ì§€ ë‚´ìš©ì„ ë¹„ë™ê¸°ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
        # í˜ì´ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        page_url = f"{self.base_url}/pages/{page_id}"
        async with session.get(page_url, headers=self.headers, timeout=30) as response:
            if response.status != 200:
                raise Exception(f"í˜ì´ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {response.status}")
            
            page_data = await response.json()
        
        # í˜ì´ì§€ ì œëª© ì¶”ì¶œ
        title = "ì œëª© ì—†ìŒ"
        if "properties" in page_data:
            for prop_name, prop_data in page_data["properties"].items():
                if prop_data.get("type") == "title" and prop_data.get("title"):
                    title = self.extract_rich_text(prop_data["title"])
                    break
        
        # í˜ì´ì§€ ë¸”ë¡ ê°€ì ¸ì˜¤ê¸°
        blocks = await self.get_block_children(session, page_id)
        
        # ë¸”ë¡ ë‚´ìš© ì²˜ë¦¬
        content_parts = []
        for block in blocks:
            content_parts.extend(self.process_block_content(block))
        
        content = "\\n\\n".join(content_parts)
        
        # Document ê°ì²´ ìƒì„±
        # í˜ì´ì§€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        page_metadata = await self.get_page_metadata(session, page_id)
        
        doc = Document(
            page_content=content,
            metadata={
                "title": title,
                "source": "notion",
                "page_id": page_id,
                "block_count": len(blocks),
                "last_modified": page_metadata.get('last_edited_time', ''),
                "created_time": page_metadata.get('created_time', '')
            }
        )
        
        return doc

    async def load_all_pages(self, since: Optional[str] = None, check_updates: bool = True) -> List[Document]:
        """ëª¨ë“  Notion í˜ì´ì§€ë¥¼ ë³‘ë ¬ë¡œ ë¡œë“œí•©ë‹ˆë‹¤. 
        
        Args:
            since: ISO 8601 í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´. ì´ ì‹œê°„ ì´í›„ì— ìˆ˜ì •ëœ í˜ì´ì§€ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            check_updates: Trueë©´ í˜ì´ì§€ ì—…ë°ì´íŠ¸ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
        """
        page_ids = self.get_page_ids_from_env()
        
        if not page_ids:
            print("âš ï¸ ì„¤ì •ëœ Notion í˜ì´ì§€ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        print(f"ğŸ” ì´ {len(page_ids)}ê°œì˜ Notion í˜ì´ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        
        # since íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ í•„í„°ë§ëœ í˜ì´ì§€ë§Œ ê°€ì ¸ì˜¤ê¸°
        if since:
            print(f"ğŸ“… {since} ì´í›„ì— ìˆ˜ì •ëœ í˜ì´ì§€ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.")
            filtered_page_ids = await self._filter_pages_by_last_edited_time(page_ids, since)
            if not filtered_page_ids:
                print("ğŸ“… ì§€ì •ëœ ì‹œê°„ ì´í›„ì— ìˆ˜ì •ëœ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            page_ids = filtered_page_ids
            print(f"ğŸ” í•„í„°ë§ í›„ {len(page_ids)}ê°œì˜ í˜ì´ì§€ê°€ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for i, page_id in enumerate(page_ids, 1):
                print(f"ğŸ“„ í˜ì´ì§€ {i}/{len(page_ids)} ë¡œë“œ ì¤€ë¹„... (ID: {page_id})")
                tasks.append(self.load_page_content(session, page_id))
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            docs = []
            for i, result in enumerate(results, 1):
                if isinstance(result, Exception):
                    print(f"âŒ í˜ì´ì§€ {i} ë¡œë“œ ì‹¤íŒ¨: {result}")
                else:
                    print(f"âœ… í˜ì´ì§€ {i} ë¡œë“œ ì™„ë£Œ: {result.metadata.get('title', 'ì œëª© ì—†ìŒ')}")
                    docs.append(result)
            
            return docs

    async def _filter_pages_by_last_edited_time(self, page_ids: List[str], since: str) -> List[str]:
        """ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ í˜ì´ì§€ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."""
        filtered_ids = []
        
        async with aiohttp.ClientSession() as session:
            for page_id in page_ids:
                try:
                    # í˜ì´ì§€ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    page_metadata = await self.get_page_metadata(session, page_id)
                    last_edited_time = page_metadata.get('last_edited_time')
                    
                    if last_edited_time and last_edited_time > since:
                        filtered_ids.append(page_id)
                        print(f"âœ… í˜ì´ì§€ {page_id}ê°€ {since} ì´í›„ì— ìˆ˜ì •ë¨: {last_edited_time}")
                    else:
                        print(f"â­ï¸ í˜ì´ì§€ {page_id}ëŠ” {since} ì´í›„ì— ìˆ˜ì •ë˜ì§€ ì•ŠìŒ: {last_edited_time}")
                        
                except Exception as e:
                    print(f"âŒ í˜ì´ì§€ {page_id} í•„í„°ë§ ì‹¤íŒ¨: {e}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ í¬í•¨
                    filtered_ids.append(page_id)
                
                await asyncio.sleep(0.1)  # Rate limit protection
        
        return filtered_ids