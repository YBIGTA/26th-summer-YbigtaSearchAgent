"""
UnifiedChromaAdapter - unified_chroma_db í˜¸í™˜ì„± ì–´ëŒ‘í„°

ê¸°ì¡´ unified_chroma_dbì˜ ë°ì´í„° êµ¬ì¡°ë¥¼ í˜„ì¬ ì‹œìŠ¤í…œê³¼ í˜¸í™˜ë˜ë„ë¡ 
ë³€í™˜í•˜ëŠ” ì–´ëŒ‘í„° íŒ¨í„´ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

- ChromaDB ë©”íƒ€ë°ì´í„°ë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•ŠìŒ
- ëŸ°íƒ€ì„ì— í˜¸í™˜ì„± ë ˆì´ì–´ ì œê³µ  
- ê¸°ì¡´ ë°ì´í„° ë¬´ì†ì‹¤ ë³´ì¥
"""

import os
import hashlib
import json
import sqlite3
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

try:
    import chromadb
    from chromadb.config import Settings
    CHROMADB_AVAILABLE = True
except ImportError:
    chromadb = None
    Settings = None
    CHROMADB_AVAILABLE = False

from langchain_core.documents import Document


class UnifiedChromaAdapter:
    """unified_chroma_dbì™€ í˜„ì¬ ì‹œìŠ¤í…œ ê°„ì˜ í˜¸í™˜ì„± ì–´ëŒ‘í„°"""
    
    def __init__(self, unified_db_path: str = "data/unified_chroma_db/unified_chroma_db"):
        self.unified_db_path = unified_db_path
        self.available = CHROMADB_AVAILABLE and os.path.exists(unified_db_path)
        
        if not self.available:
            print(f"âš ï¸ Unified ChromaDBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {unified_db_path}")
            return
            
        # ê°€ìƒ ë©”íƒ€ë°ì´í„° ì €ì¥ì†Œ (document_metadata.json í˜¸í™˜)
        self.virtual_metadata = {}
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.client = chromadb.PersistentClient(
                path=unified_db_path,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=False  # ì½ê¸° ì „ìš©
                )
            )
            self.collection = self._get_unified_collection()
            
            # ì´ˆê¸°í™” ì‹œ ê°€ìƒ ë©”íƒ€ë°ì´í„° ìƒì„±
            self._generate_virtual_metadata()
            
        except Exception as e:
            print(f"âŒ Unified ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.available = False
    
    def _get_unified_collection(self):
        """unified_chroma_dbì˜ ì»¬ë ‰ì…˜ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        collections = self.client.list_collections()
        if not collections:
            print("âŒ unified_chroma_dbì— ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # ì²« ë²ˆì§¸ ì»¬ë ‰ì…˜ ì‚¬ìš© (ë³´í†µ unified_knowledge_db)
        collection = collections[0]
        print(f"âœ… Unified ì»¬ë ‰ì…˜ ë¡œë“œ: {collection.name}")
        return collection
    
    def generate_doc_id_from_source(self, source: str) -> str:
        """unified_dbì˜ sourceë¥¼ í˜„ì¬ ì‹œìŠ¤í…œ doc_id í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if source.startswith('https://github.com/YBIGTA/'):
            repo_name = source.split('/')[-1]
            return f"github:github_{repo_name}"
        elif source.startswith('notion_page_'):
            page_id = source.replace('notion_page_', '')
            return f"notion:{page_id}"
        elif source.endswith('.pdf') or source.endswith('.docx') or source.endswith('.xlsx'):
            return source  # íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        else:
            # ê¸°íƒ€ ì†ŒìŠ¤ëŠ” í•´ì‹œ ê¸°ë°˜ ID ìƒì„±
            return f"unified:{hashlib.md5(source.encode()).hexdigest()[:8]}"
    
    def _generate_virtual_metadata(self):
        """ê¸°ì¡´ ChromaDB ë°ì´í„°ì—ì„œ ê°€ìƒ ë©”íƒ€ë°ì´í„° ìƒì„±"""
        if not self.collection:
            return
            
        print("ğŸ”„ ê°€ìƒ document_metadata ìƒì„± ì¤‘...")
        
        try:
            # SQLiteì—ì„œ ì§ì ‘ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ë” íš¨ìœ¨ì )
            sqlite_path = os.path.join(self.unified_db_path, "chroma.sqlite3")
            conn = sqlite3.connect(sqlite_path)
            cursor = conn.cursor()
            
            # ì†ŒìŠ¤ë³„ë¡œ ê·¸ë£¹í•‘ëœ ë°ì´í„° ì¡°íšŒ
            cursor.execute('''
                SELECT 
                    em_source.string_value as source,
                    em_title.string_value as title,
                    e.created_at,
                    GROUP_CONCAT(e.embedding_id) as embedding_ids,
                    COUNT(*) as chunk_count
                FROM embeddings e
                JOIN embedding_metadata em_source ON e.id = em_source.id AND em_source.key = 'source'
                LEFT JOIN embedding_metadata em_title ON e.id = em_title.id AND em_title.key = 'title'
                GROUP BY em_source.string_value, em_title.string_value
                ORDER BY e.created_at DESC
            ''')
            
            source_groups = cursor.fetchall()
            
            for source_data in source_groups:
                source, title, created_at, embedding_ids, chunk_count = source_data
                
                # doc_id ìƒì„±
                doc_id = self.generate_doc_id_from_source(source)
                
                # ì»¨í…ì¸  í•´ì‹œ ìƒì„± (ì†ŒìŠ¤ ê¸°ë°˜)
                content_hash = hashlib.sha256(f"{source}:{title}:{chunk_count}".encode()).hexdigest()
                
                # ê°€ìƒ ë©”íƒ€ë°ì´í„° ì €ì¥
                self.virtual_metadata[doc_id] = {
                    'content_hash': content_hash,
                    'last_updated': created_at or datetime.now().isoformat(),
                    'source': self._normalize_source_type(source),
                    'title': title or 'Unknown',
                    'chunk_count': chunk_count,
                    'original_source': source  # ì›ë³¸ ì†ŒìŠ¤ ë³´ì¡´
                }
            
            conn.close()
            print(f"âœ… {len(self.virtual_metadata)}ê°œ ë¬¸ì„œì˜ ê°€ìƒ ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ê°€ìƒ ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _normalize_source_type(self, source: str) -> str:
        """ì†ŒìŠ¤ë¥¼ í‘œì¤€ íƒ€ì…ìœ¼ë¡œ ì •ê·œí™”"""
        if source.startswith('https://github.com/'):
            return 'github'
        elif source.startswith('notion_page_'):
            return 'notion'
        elif any(source.endswith(ext) for ext in ['.pdf', '.docx', '.xlsx', '.pptx']):
            return 'file'
        else:
            return 'unknown'
    
    def get_virtual_metadata(self) -> Dict[str, Dict[str, Any]]:
        """í˜„ì¬ ì‹œìŠ¤í…œ í˜¸í™˜ í˜•ì‹ì˜ ê°€ìƒ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
        return self.virtual_metadata.copy()
    
    def save_virtual_metadata_to_file(self, file_path: str):
        """ê°€ìƒ ë©”íƒ€ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (í˜¸í™˜ì„± í™•ì¸ìš©)"""
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(self.virtual_metadata, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“„ ê°€ìƒ ë©”íƒ€ë°ì´í„° ì €ì¥: {file_path}")
    
    def get_documents_by_source(self, source_type: str) -> List[str]:
        """íŠ¹ì • ì†ŒìŠ¤ íƒ€ì…ì˜ ë¬¸ì„œ ëª©ë¡ ë°˜í™˜"""
        return [
            doc_id for doc_id, metadata in self.virtual_metadata.items()
            if metadata.get('source') == source_type
        ]
    
    def check_document_exists(self, doc_id: str) -> bool:
        """ë¬¸ì„œê°€ unified_dbì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        return doc_id in self.virtual_metadata
    
    def get_source_statistics(self) -> Dict[str, Any]:
        """ì†ŒìŠ¤ë³„ í†µê³„ ë°˜í™˜"""
        stats = {}
        for doc_id, metadata in self.virtual_metadata.items():
            source_type = metadata.get('source', 'unknown')
            if source_type not in stats:
                stats[source_type] = {
                    'document_count': 0,
                    'total_chunks': 0,
                    'last_updated': None
                }
            
            stats[source_type]['document_count'] += 1
            stats[source_type]['total_chunks'] += metadata.get('chunk_count', 0)
            
            last_updated = metadata.get('last_updated')
            if last_updated and (not stats[source_type]['last_updated'] or 
                                last_updated > stats[source_type]['last_updated']):
                stats[source_type]['last_updated'] = last_updated
        
        return stats
    
    def search_documents(self, query: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """unified_dbì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ (ChromaDB ê²€ìƒ‰ ë˜í•‘)"""
        if not self.collection:
            return []
        
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k,
                include=['documents', 'metadatas', 'distances']
            )
            
            formatted_results = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    metadata = results['metadatas'][0][i] if results['metadatas'] else {}
                    distance = results['distances'][0][i] if results['distances'] else 0.0
                    
                    # ê°€ìƒ doc_id ìƒì„±
                    original_source = metadata.get('source', 'unknown')
                    virtual_doc_id = self.generate_doc_id_from_source(original_source)
                    
                    formatted_results.append({
                        'document': Document(page_content=doc, metadata=metadata),
                        'score': 1.0 - distance,  # ê±°ë¦¬ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜
                        'content': doc,
                        'metadata': {**metadata, 'doc_id': virtual_doc_id},
                        'type': 'vector_unified'
                    })
            
            return formatted_results
            
        except Exception as e:
            print(f"âŒ Unified DB ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []